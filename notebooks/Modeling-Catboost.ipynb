{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "import hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.model_selection\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import model_selection , metrics   #Additional scklearn functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imput_strategy = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('../data/merged_data/train.pkl')\n",
    "test = pd.read_pickle('../data/merged_data/test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "y_train = train['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to try:\n",
    "* optimize aucroc with keras and batch methods\n",
    "* SVM / rank SVM (https://github.com/rdipietro/pyrvm)\n",
    "* try separate models on separate variables + stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features : \n",
    "* NLP on COMMENTAIRE_BI\n",
    "* Extract options from OPTION (pas sur que ce soit util, peut être juste check la qualité)\n",
    "* features from history\n",
    "\n",
    "\n",
    "\n",
    "* check for intervention in test without contracts and to handle them\n",
    "* add combinations of categorical features (see paribas example on catboost site)\n",
    "* select only best features (feature_importance ?)\n",
    "* try to put random nas in train for handling missing contracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fails:\n",
    "* one model with selectKbest on modalities vs one model on dimensionality reduction with group rare modalities\n",
    "    * dimensionality reduction don't bring much value here (mb MCA)\n",
    "    * select k best fails with 5k categories, which is not enough to be interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = ['INSTANCE_ID', #460k modalities, not usable as a feature\n",
    "        'INCIDENT_NUMBER']\n",
    "drop_atm = [#'AUTEUR_INCIDENT', # 2088 modalities\n",
    "            'TYPE_VOIE',\n",
    "#            'NATURE_CODE', # 313 modalities, need to be splitted in 5 modalities\n",
    "#            'MARQUE_LIB', # 167 modalities\n",
    "#            'OPTION', # 80 modalities, extract options\n",
    "#            'MODELE_CODE', # 10k modalities\n",
    "#            'COMMENTAIRE_BI', # NLP 400k modalities\n",
    "#             'RESOURCE_ID', # 4033 modalities\n",
    "            'CODE_POSTAL', # 5800 modalities (only get first 2 numbers ?)\n",
    "            'L2_ORGA_CODE_POSTAL', # 147 modalities (might be redondent with L2_ORGANISATION_ID)\n",
    "#            'L2_ORGANISATION_ID' #151 modalities\n",
    "            'L2_ORGA_VILLE', # 146, might be redondent with other organisation variables\n",
    "#            'RACHAT_CODE' # 312 modalities (try binarising ?)         \n",
    "#            'CODE_INSTALLATION' # 17 modalities\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(drop + drop_atm + ['target'], axis=1, inplace=True)\n",
    "test.drop(drop + drop_atm, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### imputation of missing data\n",
    "\n",
    "TODO: try imputing test based on test values, not train <br>\n",
    "TODO: try diffrent strategy on imputing datas from contract since missing are present only in test set<BR>\n",
    "TODO: try creating data with missing contract in train sample and do not fill the missing in test<br>\n",
    "TODO: try imputing specific na value for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_selected_variables(df, test, categ, quanti, dates):\n",
    "    _df = df.copy()\n",
    "    _test = test.copy() if test is not None else None\n",
    "    \n",
    "    replace = _df[categ].mode()\n",
    "    replace_values = {k:v.iloc[0] for k,v in replace.items()}\n",
    "    _df.fillna(replace_values, inplace=True)\n",
    "\n",
    "    replace_quanti = _df[quanti].mean()\n",
    "    _df.fillna(replace_quanti, inplace=True)\n",
    "\n",
    "    _df[dates] = _df[dates].fillna(method='pad')\n",
    "    \n",
    "    if test is not None:\n",
    "        \n",
    "        _test.fillna(replace_values, inplace=True)\n",
    "        _test.fillna(replace_quanti, inplace=True)\n",
    "        _test[dates] = _df[dates].fillna(method='pad')\n",
    "    \n",
    "    return _df, _test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace = train[categoricals].mode()\n",
    "#replace_values = {k:v.iloc[0] for k,v in replace.items()}\n",
    "def impute_contract_variables(df):\n",
    "    df_ = df.copy()\n",
    "    \n",
    "    for var in categ_contract:\n",
    "        _df[var] = _df[var].cat.add_categories(['NAN'])\n",
    "        _df[var].fillna('NAN', inplace=True)\n",
    "\n",
    "    _df[quanti_contract].fillna(-999, inplace=True)\n",
    "    _df[date_contract].fillna(datetime.datetime(1970, 1, 1), inplace=True)\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = list(train.columns[train.dtypes == 'category'])\n",
    "quantitative = ['NB_PASSAGE', 'POINTS_FIDEL', 'CONTRAT_TARIF', 'PRIX_FACTURE']\n",
    "dates = list(train.columns[train.dtypes == 'datetime64[ns]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_variables = [ 'UPD_DATE', 'DATE_DEBUT', 'DATE_FIN', 'STS_CODE', 'OPTION', 'FORMULE', 'CONTRAT_TARIF', 'PRIX_FACTURE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute without contract\n",
    "categ_to_impute = list(set(categoricals) - set(contract_variables))\n",
    "quanti_to_impute = list(set(quantitative) - set(contract_variables))\n",
    "date_to_impute = list(set(dates) - set(contract_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute contract\n",
    "categ_contract = list(set(categoricals).intersection(set(contract_variables)))\n",
    "quanti_contract = list(set(quantitative).intersection(set(contract_variables)))\n",
    "date_contract = list(set(dates).intersection(set(contract_variables)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test are filled with values taken from train\n",
    "#contract and other variables are imputed together\n",
    "if imput_strategy == 1:\n",
    "    train, test = impute_selected_variables(train, test, categoricals, quantitative, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test are filled with values taken on their own values\n",
    "#contract and other variables are imputed together\n",
    "if imput_strategy == 2:\n",
    "    train, _ = impute_selected_variables(train, None, categoricals, quantitative, dates)\n",
    "    test, _ = impute_selected_variables(test, None, categoricals, quantitative, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test are filled with values taken from train\n",
    "#contract and other variables are imputed separatly\n",
    "if imput_strategy == 3:\n",
    "    train, test = impute_selected_variables(train, test, categ_to_impute, quanti_to_impute, date_to_impute)\n",
    "    train = impute_contract_variables(train)\n",
    "    test = impute_contract_variables(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test are filled on their own values\n",
    "#contract and other variables are imputed separatly\n",
    "if imput_strategy == 4:\n",
    "    train, _ = impute_selected_variables(train, None, categ_to_impute, quanti_to_impute, date_to_impute)\n",
    "    test, _ = impute_selected_variables(test, None, categ_to_impute, quanti_to_impute, date_to_impute)\n",
    "    train = impute_contract_variables(train)\n",
    "    test = impute_contract_variables(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Feature ingineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commentaire_bi(df):\n",
    "    _df = df.copy()\n",
    "    \n",
    "    _df.COMMENTAIRE_BI = _df.COMMENTAIRE_BI.str.upper()\n",
    "    COMMENTAIRE_BI_vc = _df.COMMENTAIRE_BI.value_counts()\n",
    "    common_commentaire_bi = COMMENTAIRE_BI_vc[COMMENTAIRE_BI_vc > 100].index\n",
    "    _df['COMMENTAIRE_BI_common'] = _df.COMMENTAIRE_BI.where(_df.COMMENTAIRE_BI.isin(common_commentaire_bi), \"Rare\")\n",
    "    \n",
    "    _df['nb_char_commentaire'] = [len(txt) for txt in _df.COMMENTAIRE_BI]\n",
    "    _df['nb_mots_commentaire'] = [len(txt.split()) for txt in _df.COMMENTAIRE_BI]\n",
    "    _df['has_number_commentaire'] = [any(char.isdigit() for char in txt) for txt in _df.COMMENTAIRE_BI]\n",
    "    _df['is_empty_commentaire'] = [(txt == '.') for txt in _df.COMMENTAIRE_BI]\n",
    "    _df.drop('COMMENTAIRE_BI', axis=1, inplace=True)\n",
    "    \n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nature_code_split(df):\n",
    "    _df = df.copy()\n",
    "    nature_code_splitted = [nc.split('-') for nc in df.NATURE_CODE]\n",
    "    nature_code_df = pd.DataFrame(nature_code_splitted, columns=['nc_1', 'nc_2', 'nc_3', 'nc_4', 'nc_5'])\n",
    "    nature_code_df.fillna('-1', inplace=True)\n",
    "    for nc_i in ['nc_1', 'nc_2', 'nc_3', 'nc_4', 'nc_5']:\n",
    "        nature_code_df[nc_i] = nature_code_df[nc_i].astype('category')\n",
    "    \n",
    "    #_df.drop('NATURE_CODE', axis=1, inplace=True)\n",
    "    _df = _df.merge(nature_code_df, left_index=True, right_index=True)\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: use dt series accessor\n",
    "def add_dates_features(data):\n",
    "    data['age_installation'] = (data['CRE_DATE_GZL'] - data['INSTALL_DATE']).dt.days // 365\n",
    "    data['mois_appel'] = data['CRE_DATE_GZL'].map(lambda x: x.month)\n",
    "    data['joursemaine_appel'] = data['CRE_DATE_GZL'].map(lambda x: x.isoweekday()) #integer, might be considered categorical\n",
    "    data['jour_appel'] = data['CRE_DATE_GZL'].map(lambda x: x.day)\n",
    "    data['mois_intervention'] = data['SCHEDULED_START_DATE'].map(lambda x: x.month)\n",
    "    data['joursemaine_intervention'] = data['SCHEDULED_START_DATE'].map(lambda x: x.isoweekday()) #integer, might be considered categorical\n",
    "    data['jour_intervention'] = data['SCHEDULED_START_DATE'].map(lambda x: x.day)\n",
    "    data['duree_avant_intervention'] = (data['SCHEDULED_START_DATE'] - data['CRE_DATE_GZL']).dt.days\n",
    "    data['duree_prevue'] = (data['SCHEDULED_END_DATE'] - data['SCHEDULED_START_DATE']).dt.days\n",
    "    data['temps_depuis_debut_contrat'] = (data['CRE_DATE_GZL'] - data['DATE_DEBUT']).dt.days\n",
    "    data['temps_jusqua_fin_contrat'] = (data['CRE_DATE_GZL'] - data['DATE_FIN']).dt.days  #souvent nan ? (mettre 0)\n",
    "    data['temps_depuis_maj_contrat'] = (data['CRE_DATE_GZL'] - data['UPD_DATE']).dt.days \n",
    "\n",
    "    data.drop(['CRE_DATE_GZL', 'INSTALL_DATE', 'SCHEDULED_START_DATE', 'SCHEDULED_END_DATE', 'DATE_DEBUT', 'DATE_FIN', 'UPD_DATE'], axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mots en particulier\n",
    "#créer un dictionnaire et compter (count et garder les must ? voir la diff entre les cas + et - ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "\n",
    "# (history) temps depuis dernière visite (pas forcément dispo sur le test)\n",
    "# (history) déjà eu une casse sur ce matériel\n",
    "# (history) temps depuis dernière casse\n",
    "# (history) la dernière visite date de moins de 6 mois\n",
    "# (history) nb interventions faires par la ressource\n",
    "# (history) temps depuis la première intervention de la ressource\n",
    "# (contract history) nb de fois que le contrat a été mis à jour sur les X dernières années"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = commentaire_bi(train)\n",
    "train = nature_code_split(train)\n",
    "train = add_dates_features(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = commentaire_bi(test)\n",
    "test = nature_code_split(test)\n",
    "test = add_dates_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop variables\n",
    "drop = ['joursemaine_appel', \n",
    "'USAGE_LOCAL', \n",
    "'nc_4', \n",
    "'is_empty_commentaire', \n",
    "'duree_prevue', \n",
    "'nc_1']\n",
    "\n",
    "train.drop(drop, axis=1,inplace=True)\n",
    "test.drop(drop, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelisation\n",
    "\n",
    "TODO:\n",
    "* one hot encoding low modalities: keep for grid search (no ideal value found right now, try 3, 5, ... 9)\n",
    "* group rare modalities: doesn't seem to improve the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split train / val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for item in categoricals:\n",
    "#    train[item] = train[item].cat.codes +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train in train, cv (will be replaced by cross validation for parameters tuning)\n",
    "# stratify ?\n",
    "X_train_train, X_train_val, y_train_train, y_train_val = sklearn.model_selection.train_test_split(train, y_train, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_ratio =  sum(y_train==0) / sum(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combinations_ctr for list of variables ?\n",
    "model = CatBoostClassifier(\n",
    "    iterations=200,\n",
    "#    one_hot_max_size=3,\n",
    "#    learning_rate=0.16,\n",
    "    depth=8,\n",
    "    eval_metric=\"AUC\",\n",
    "    random_seed=42,\n",
    "    od_type='Iter',\n",
    "    od_wait=40,\n",
    "    use_best_model=True\n",
    "#    scale_pos_weight=pos_neg_ratio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = train.select_dtypes(include=['category', 'bool', 'object']).columns\n",
    "categorical_features_indices = [X_train_train.columns.get_loc(cat) for cat in categoricals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.312918\n",
      "0:\ttest: 0.6998147\tbest: 0.6998147 (0)\ttotal: 4.74s\tremaining: 15m 43s\n",
      "1:\ttest: 0.7093075\tbest: 0.7093075 (1)\ttotal: 9.51s\tremaining: 15m 41s\n",
      "2:\ttest: 0.7136381\tbest: 0.7136381 (2)\ttotal: 14.4s\tremaining: 15m 48s\n",
      "3:\ttest: 0.7161682\tbest: 0.7161682 (3)\ttotal: 19.1s\tremaining: 15m 33s\n",
      "4:\ttest: 0.7241421\tbest: 0.7241421 (4)\ttotal: 24.4s\tremaining: 15m 52s\n",
      "5:\ttest: 0.7277995\tbest: 0.7277995 (5)\ttotal: 30.6s\tremaining: 16m 29s\n",
      "6:\ttest: 0.7292006\tbest: 0.7292006 (6)\ttotal: 36.2s\tremaining: 16m 37s\n",
      "7:\ttest: 0.7293384\tbest: 0.7293384 (7)\ttotal: 41.5s\tremaining: 16m 36s\n",
      "8:\ttest: 0.7321992\tbest: 0.7321992 (8)\ttotal: 47.9s\tremaining: 16m 56s\n",
      "9:\ttest: 0.7324205\tbest: 0.7324205 (9)\ttotal: 53.3s\tremaining: 16m 52s\n",
      "10:\ttest: 0.7366587\tbest: 0.7366587 (10)\ttotal: 58.7s\tremaining: 16m 49s\n",
      "11:\ttest: 0.7389512\tbest: 0.7389512 (11)\ttotal: 1m 5s\tremaining: 17m 6s\n",
      "12:\ttest: 0.7433079\tbest: 0.7433079 (12)\ttotal: 1m 11s\tremaining: 17m 10s\n",
      "13:\ttest: 0.7448536\tbest: 0.7448536 (13)\ttotal: 1m 17s\tremaining: 17m 11s\n",
      "14:\ttest: 0.7450495\tbest: 0.7450495 (14)\ttotal: 1m 23s\tremaining: 17m 15s\n",
      "15:\ttest: 0.7471731\tbest: 0.7471731 (15)\ttotal: 1m 33s\tremaining: 17m 51s\n",
      "16:\ttest: 0.7472413\tbest: 0.7472413 (16)\ttotal: 1m 40s\tremaining: 17m 59s\n",
      "17:\ttest: 0.7480737\tbest: 0.7480737 (17)\ttotal: 1m 50s\tremaining: 18m 36s\n",
      "18:\ttest: 0.7486311\tbest: 0.7486311 (18)\ttotal: 1m 59s\tremaining: 19m 2s\n",
      "19:\ttest: 0.7494465\tbest: 0.7494465 (19)\ttotal: 2m 12s\tremaining: 19m 49s\n",
      "20:\ttest: 0.7496089\tbest: 0.7496089 (20)\ttotal: 2m 21s\tremaining: 20m 3s\n",
      "21:\ttest: 0.7496086\tbest: 0.7496089 (20)\ttotal: 2m 29s\tremaining: 20m 5s\n",
      "22:\ttest: 0.7497287\tbest: 0.7497287 (22)\ttotal: 2m 36s\tremaining: 20m 5s\n",
      "23:\ttest: 0.7497801\tbest: 0.7497801 (23)\ttotal: 2m 44s\tremaining: 20m 5s\n",
      "24:\ttest: 0.7501221\tbest: 0.7501221 (24)\ttotal: 2m 54s\tremaining: 20m 18s\n",
      "25:\ttest: 0.7513034\tbest: 0.7513034 (25)\ttotal: 3m\tremaining: 20m 6s\n",
      "26:\ttest: 0.7526874\tbest: 0.7526874 (26)\ttotal: 3m 7s\tremaining: 19m 58s\n",
      "27:\ttest: 0.7527441\tbest: 0.7527441 (27)\ttotal: 3m 14s\tremaining: 19m 54s\n",
      "28:\ttest: 0.7528797\tbest: 0.7528797 (28)\ttotal: 3m 20s\tremaining: 19m 44s\n",
      "29:\ttest: 0.7529437\tbest: 0.7529437 (29)\ttotal: 3m 27s\tremaining: 19m 35s\n",
      "30:\ttest: 0.7529694\tbest: 0.7529694 (30)\ttotal: 3m 34s\tremaining: 19m 27s\n",
      "31:\ttest: 0.7529678\tbest: 0.7529694 (30)\ttotal: 3m 39s\tremaining: 19m 12s\n",
      "32:\ttest: 0.7530503\tbest: 0.7530503 (32)\ttotal: 3m 45s\tremaining: 19m\n",
      "33:\ttest: 0.7531027\tbest: 0.7531027 (33)\ttotal: 3m 49s\tremaining: 18m 42s\n",
      "34:\ttest: 0.7531929\tbest: 0.7531929 (34)\ttotal: 3m 55s\tremaining: 18m 29s\n",
      "35:\ttest: 0.7532281\tbest: 0.7532281 (35)\ttotal: 4m 1s\tremaining: 18m 18s\n",
      "36:\ttest: 0.7548905\tbest: 0.7548905 (36)\ttotal: 4m 6s\tremaining: 18m 6s\n",
      "37:\ttest: 0.7549686\tbest: 0.7549686 (37)\ttotal: 4m 12s\tremaining: 17m 57s\n",
      "38:\ttest: 0.7550020\tbest: 0.7550020 (38)\ttotal: 4m 17s\tremaining: 17m 43s\n",
      "39:\ttest: 0.7549682\tbest: 0.7550020 (38)\ttotal: 4m 22s\tremaining: 17m 30s\n",
      "40:\ttest: 0.7554013\tbest: 0.7554013 (40)\ttotal: 4m 29s\tremaining: 17m 25s\n",
      "41:\ttest: 0.7555963\tbest: 0.7555963 (41)\ttotal: 4m 36s\tremaining: 17m 19s\n",
      "42:\ttest: 0.7557192\tbest: 0.7557192 (42)\ttotal: 4m 40s\tremaining: 17m 5s\n",
      "43:\ttest: 0.7557494\tbest: 0.7557494 (43)\ttotal: 4m 46s\tremaining: 16m 55s\n",
      "44:\ttest: 0.7557554\tbest: 0.7557554 (44)\ttotal: 4m 51s\tremaining: 16m 42s\n",
      "45:\ttest: 0.7557689\tbest: 0.7557689 (45)\ttotal: 4m 56s\tremaining: 16m 33s\n",
      "46:\ttest: 0.7557818\tbest: 0.7557818 (46)\ttotal: 5m 1s\tremaining: 16m 21s\n",
      "47:\ttest: 0.7568909\tbest: 0.7568909 (47)\ttotal: 5m 8s\tremaining: 16m 16s\n",
      "48:\ttest: 0.7580144\tbest: 0.7580144 (48)\ttotal: 5m 16s\tremaining: 16m 15s\n",
      "49:\ttest: 0.7580138\tbest: 0.7580144 (48)\ttotal: 5m 23s\tremaining: 16m 8s\n",
      "50:\ttest: 0.7580512\tbest: 0.7580512 (50)\ttotal: 5m 28s\tremaining: 16m\n",
      "51:\ttest: 0.7605366\tbest: 0.7605366 (51)\ttotal: 5m 35s\tremaining: 15m 55s\n",
      "52:\ttest: 0.7605651\tbest: 0.7605651 (52)\ttotal: 5m 42s\tremaining: 15m 49s\n",
      "53:\ttest: 0.7606459\tbest: 0.7606459 (53)\ttotal: 5m 49s\tremaining: 15m 44s\n",
      "54:\ttest: 0.7608106\tbest: 0.7608106 (54)\ttotal: 5m 57s\tremaining: 15m 42s\n",
      "55:\ttest: 0.7611140\tbest: 0.7611140 (55)\ttotal: 6m 13s\tremaining: 16m\n",
      "56:\ttest: 0.7618091\tbest: 0.7618091 (56)\ttotal: 6m 22s\tremaining: 16m\n",
      "57:\ttest: 0.7619854\tbest: 0.7619854 (57)\ttotal: 6m 28s\tremaining: 15m 51s\n",
      "58:\ttest: 0.7625931\tbest: 0.7625931 (58)\ttotal: 6m 35s\tremaining: 15m 44s\n",
      "59:\ttest: 0.7626857\tbest: 0.7626857 (59)\ttotal: 6m 42s\tremaining: 15m 39s\n",
      "60:\ttest: 0.7628214\tbest: 0.7628214 (60)\ttotal: 6m 48s\tremaining: 15m 31s\n",
      "61:\ttest: 0.7628563\tbest: 0.7628563 (61)\ttotal: 6m 55s\tremaining: 15m 25s\n",
      "62:\ttest: 0.7629614\tbest: 0.7629614 (62)\ttotal: 7m 3s\tremaining: 15m 20s\n",
      "63:\ttest: 0.7629572\tbest: 0.7629614 (62)\ttotal: 7m 10s\tremaining: 15m 13s\n",
      "64:\ttest: 0.7630327\tbest: 0.7630327 (64)\ttotal: 7m 16s\tremaining: 15m 6s\n",
      "65:\ttest: 0.7636244\tbest: 0.7636244 (65)\ttotal: 7m 24s\tremaining: 15m 2s\n",
      "66:\ttest: 0.7636543\tbest: 0.7636543 (66)\ttotal: 7m 31s\tremaining: 14m 55s\n",
      "67:\ttest: 0.7636724\tbest: 0.7636724 (67)\ttotal: 7m 38s\tremaining: 14m 49s\n",
      "68:\ttest: 0.7636726\tbest: 0.7636726 (68)\ttotal: 7m 45s\tremaining: 14m 44s\n",
      "69:\ttest: 0.7640481\tbest: 0.7640481 (69)\ttotal: 7m 51s\tremaining: 14m 36s\n",
      "70:\ttest: 0.7640217\tbest: 0.7640481 (69)\ttotal: 7m 59s\tremaining: 14m 31s\n",
      "71:\ttest: 0.7640511\tbest: 0.7640511 (71)\ttotal: 8m 5s\tremaining: 14m 23s\n",
      "72:\ttest: 0.7640785\tbest: 0.7640785 (72)\ttotal: 8m 12s\tremaining: 14m 16s\n",
      "73:\ttest: 0.7646302\tbest: 0.7646302 (73)\ttotal: 8m 21s\tremaining: 14m 14s\n",
      "74:\ttest: 0.7651119\tbest: 0.7651119 (74)\ttotal: 8m 29s\tremaining: 14m 9s\n",
      "75:\ttest: 0.7651417\tbest: 0.7651417 (75)\ttotal: 8m 37s\tremaining: 14m 3s\n",
      "76:\ttest: 0.7652876\tbest: 0.7652876 (76)\ttotal: 8m 45s\tremaining: 13m 59s\n",
      "77:\ttest: 0.7654519\tbest: 0.7654519 (77)\ttotal: 8m 53s\tremaining: 13m 54s\n",
      "78:\ttest: 0.7654409\tbest: 0.7654519 (77)\ttotal: 9m\tremaining: 13m 47s\n",
      "79:\ttest: 0.7654420\tbest: 0.7654519 (77)\ttotal: 9m 7s\tremaining: 13m 40s\n",
      "80:\ttest: 0.7654407\tbest: 0.7654519 (77)\ttotal: 9m 14s\tremaining: 13m 33s\n",
      "81:\ttest: 0.7654883\tbest: 0.7654883 (81)\ttotal: 9m 21s\tremaining: 13m 28s\n",
      "82:\ttest: 0.7654962\tbest: 0.7654962 (82)\ttotal: 9m 30s\tremaining: 13m 24s\n",
      "83:\ttest: 0.7655093\tbest: 0.7655093 (83)\ttotal: 9m 36s\tremaining: 13m 16s\n",
      "84:\ttest: 0.7655270\tbest: 0.7655270 (84)\ttotal: 9m 44s\tremaining: 13m 10s\n",
      "85:\ttest: 0.7655172\tbest: 0.7655270 (84)\ttotal: 9m 51s\tremaining: 13m 4s\n",
      "86:\ttest: 0.7655028\tbest: 0.7655270 (84)\ttotal: 9m 59s\tremaining: 12m 58s\n",
      "87:\ttest: 0.7655056\tbest: 0.7655270 (84)\ttotal: 10m 5s\tremaining: 12m 50s\n",
      "88:\ttest: 0.7657634\tbest: 0.7657634 (88)\ttotal: 10m 12s\tremaining: 12m 44s\n",
      "89:\ttest: 0.7664728\tbest: 0.7664728 (89)\ttotal: 10m 21s\tremaining: 12m 39s\n",
      "90:\ttest: 0.7664792\tbest: 0.7664792 (90)\ttotal: 10m 28s\tremaining: 12m 32s\n",
      "91:\ttest: 0.7664717\tbest: 0.7664792 (90)\ttotal: 10m 34s\tremaining: 12m 25s\n",
      "92:\ttest: 0.7666585\tbest: 0.7666585 (92)\ttotal: 10m 42s\tremaining: 12m 19s\n",
      "93:\ttest: 0.7666589\tbest: 0.7666589 (93)\ttotal: 10m 49s\tremaining: 12m 12s\n",
      "94:\ttest: 0.7666892\tbest: 0.7666892 (94)\ttotal: 10m 55s\tremaining: 12m 4s\n",
      "95:\ttest: 0.7666878\tbest: 0.7666892 (94)\ttotal: 11m 1s\tremaining: 11m 56s\n",
      "96:\ttest: 0.7667063\tbest: 0.7667063 (96)\ttotal: 11m 6s\tremaining: 11m 48s\n",
      "97:\ttest: 0.7667063\tbest: 0.7667063 (96)\ttotal: 11m 13s\tremaining: 11m 41s\n",
      "98:\ttest: 0.7667209\tbest: 0.7667209 (98)\ttotal: 11m 20s\tremaining: 11m 34s\n",
      "99:\ttest: 0.7667352\tbest: 0.7667352 (99)\ttotal: 11m 27s\tremaining: 11m 27s\n",
      "100:\ttest: 0.7667502\tbest: 0.7667502 (100)\ttotal: 11m 35s\tremaining: 11m 21s\n",
      "101:\ttest: 0.7667225\tbest: 0.7667502 (100)\ttotal: 11m 41s\tremaining: 11m 13s\n",
      "102:\ttest: 0.7667521\tbest: 0.7667521 (102)\ttotal: 11m 48s\tremaining: 11m 7s\n",
      "103:\ttest: 0.7667474\tbest: 0.7667521 (102)\ttotal: 11m 55s\tremaining: 11m\n",
      "104:\ttest: 0.7667237\tbest: 0.7667521 (102)\ttotal: 12m 1s\tremaining: 10m 52s\n",
      "105:\ttest: 0.7667526\tbest: 0.7667526 (105)\ttotal: 12m 8s\tremaining: 10m 46s\n",
      "106:\ttest: 0.7667600\tbest: 0.7667600 (106)\ttotal: 12m 15s\tremaining: 10m 39s\n",
      "107:\ttest: 0.7667862\tbest: 0.7667862 (107)\ttotal: 12m 21s\tremaining: 10m 31s\n",
      "108:\ttest: 0.7667737\tbest: 0.7667862 (107)\ttotal: 12m 28s\tremaining: 10m 24s\n",
      "109:\ttest: 0.7667656\tbest: 0.7667862 (107)\ttotal: 12m 35s\tremaining: 10m 18s\n",
      "110:\ttest: 0.7667393\tbest: 0.7667862 (107)\ttotal: 12m 40s\tremaining: 10m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111:\ttest: 0.7667670\tbest: 0.7667862 (107)\ttotal: 12m 47s\tremaining: 10m 2s\n",
      "112:\ttest: 0.7667685\tbest: 0.7667862 (107)\ttotal: 12m 53s\tremaining: 9m 55s\n",
      "113:\ttest: 0.7667690\tbest: 0.7667862 (107)\ttotal: 12m 59s\tremaining: 9m 48s\n",
      "114:\ttest: 0.7667607\tbest: 0.7667862 (107)\ttotal: 13m 5s\tremaining: 9m 40s\n",
      "115:\ttest: 0.7667589\tbest: 0.7667862 (107)\ttotal: 13m 11s\tremaining: 9m 33s\n",
      "116:\ttest: 0.7670066\tbest: 0.7670066 (116)\ttotal: 13m 17s\tremaining: 9m 25s\n",
      "117:\ttest: 0.7670075\tbest: 0.7670075 (117)\ttotal: 13m 24s\tremaining: 9m 18s\n",
      "118:\ttest: 0.7670005\tbest: 0.7670075 (117)\ttotal: 13m 29s\tremaining: 9m 11s\n",
      "119:\ttest: 0.7670151\tbest: 0.7670151 (119)\ttotal: 13m 34s\tremaining: 9m 2s\n",
      "120:\ttest: 0.7670786\tbest: 0.7670786 (120)\ttotal: 13m 40s\tremaining: 8m 55s\n",
      "121:\ttest: 0.7671223\tbest: 0.7671223 (121)\ttotal: 13m 46s\tremaining: 8m 48s\n",
      "122:\ttest: 0.7671418\tbest: 0.7671418 (122)\ttotal: 13m 51s\tremaining: 8m 40s\n",
      "123:\ttest: 0.7671522\tbest: 0.7671522 (123)\ttotal: 13m 58s\tremaining: 8m 33s\n",
      "124:\ttest: 0.7671705\tbest: 0.7671705 (124)\ttotal: 14m 4s\tremaining: 8m 26s\n",
      "125:\ttest: 0.7671726\tbest: 0.7671726 (125)\ttotal: 14m 9s\tremaining: 8m 19s\n",
      "126:\ttest: 0.7671896\tbest: 0.7671896 (126)\ttotal: 14m 15s\tremaining: 8m 11s\n",
      "127:\ttest: 0.7671848\tbest: 0.7671896 (126)\ttotal: 14m 21s\tremaining: 8m 4s\n",
      "128:\ttest: 0.7672145\tbest: 0.7672145 (128)\ttotal: 14m 26s\tremaining: 7m 56s\n",
      "129:\ttest: 0.7672240\tbest: 0.7672240 (129)\ttotal: 14m 32s\tremaining: 7m 49s\n",
      "130:\ttest: 0.7672020\tbest: 0.7672240 (129)\ttotal: 14m 38s\tremaining: 7m 42s\n",
      "131:\ttest: 0.7690053\tbest: 0.7690053 (131)\ttotal: 14m 43s\tremaining: 7m 34s\n",
      "132:\ttest: 0.7690259\tbest: 0.7690259 (132)\ttotal: 14m 49s\tremaining: 7m 28s\n",
      "133:\ttest: 0.7706325\tbest: 0.7706325 (133)\ttotal: 14m 56s\tremaining: 7m 21s\n",
      "134:\ttest: 0.7706243\tbest: 0.7706325 (133)\ttotal: 15m 2s\tremaining: 7m 14s\n",
      "135:\ttest: 0.7706305\tbest: 0.7706325 (133)\ttotal: 15m 8s\tremaining: 7m 7s\n",
      "136:\ttest: 0.7706789\tbest: 0.7706789 (136)\ttotal: 15m 14s\tremaining: 7m\n",
      "137:\ttest: 0.7707023\tbest: 0.7707023 (137)\ttotal: 15m 19s\tremaining: 6m 53s\n",
      "138:\ttest: 0.7708455\tbest: 0.7708455 (138)\ttotal: 15m 27s\tremaining: 6m 46s\n",
      "139:\ttest: 0.7708660\tbest: 0.7708660 (139)\ttotal: 15m 32s\tremaining: 6m 39s\n",
      "140:\ttest: 0.7708736\tbest: 0.7708736 (140)\ttotal: 15m 37s\tremaining: 6m 32s\n",
      "141:\ttest: 0.7708673\tbest: 0.7708736 (140)\ttotal: 15m 42s\tremaining: 6m 25s\n",
      "142:\ttest: 0.7709128\tbest: 0.7709128 (142)\ttotal: 15m 48s\tremaining: 6m 18s\n",
      "143:\ttest: 0.7709032\tbest: 0.7709128 (142)\ttotal: 15m 53s\tremaining: 6m 10s\n",
      "144:\ttest: 0.7711575\tbest: 0.7711575 (144)\ttotal: 15m 59s\tremaining: 6m 3s\n",
      "145:\ttest: 0.7711777\tbest: 0.7711777 (145)\ttotal: 16m 5s\tremaining: 5m 57s\n",
      "146:\ttest: 0.7711588\tbest: 0.7711777 (145)\ttotal: 16m 11s\tremaining: 5m 50s\n",
      "147:\ttest: 0.7711861\tbest: 0.7711861 (147)\ttotal: 16m 16s\tremaining: 5m 43s\n",
      "148:\ttest: 0.7713528\tbest: 0.7713528 (148)\ttotal: 16m 23s\tremaining: 5m 36s\n",
      "149:\ttest: 0.7713757\tbest: 0.7713757 (149)\ttotal: 16m 30s\tremaining: 5m 30s\n",
      "150:\ttest: 0.7713713\tbest: 0.7713757 (149)\ttotal: 16m 37s\tremaining: 5m 23s\n",
      "151:\ttest: 0.7713654\tbest: 0.7713757 (149)\ttotal: 16m 43s\tremaining: 5m 16s\n",
      "152:\ttest: 0.7713667\tbest: 0.7713757 (149)\ttotal: 16m 49s\tremaining: 5m 9s\n",
      "153:\ttest: 0.7714064\tbest: 0.7714064 (153)\ttotal: 16m 55s\tremaining: 5m 3s\n",
      "154:\ttest: 0.7716810\tbest: 0.7716810 (154)\ttotal: 17m 3s\tremaining: 4m 57s\n",
      "155:\ttest: 0.7716595\tbest: 0.7716810 (154)\ttotal: 17m 8s\tremaining: 4m 49s\n",
      "156:\ttest: 0.7719779\tbest: 0.7719779 (156)\ttotal: 17m 14s\tremaining: 4m 43s\n",
      "157:\ttest: 0.7719990\tbest: 0.7719990 (157)\ttotal: 17m 21s\tremaining: 4m 36s\n",
      "158:\ttest: 0.7720066\tbest: 0.7720066 (158)\ttotal: 17m 27s\tremaining: 4m 30s\n",
      "159:\ttest: 0.7726292\tbest: 0.7726292 (159)\ttotal: 17m 35s\tremaining: 4m 23s\n",
      "160:\ttest: 0.7726498\tbest: 0.7726498 (160)\ttotal: 17m 41s\tremaining: 4m 17s\n",
      "161:\ttest: 0.7726515\tbest: 0.7726515 (161)\ttotal: 17m 48s\tremaining: 4m 10s\n",
      "162:\ttest: 0.7726530\tbest: 0.7726530 (162)\ttotal: 17m 55s\tremaining: 4m 4s\n",
      "163:\ttest: 0.7726568\tbest: 0.7726568 (163)\ttotal: 18m 1s\tremaining: 3m 57s\n",
      "164:\ttest: 0.7727757\tbest: 0.7727757 (164)\ttotal: 18m 8s\tremaining: 3m 50s\n",
      "165:\ttest: 0.7727937\tbest: 0.7727937 (165)\ttotal: 18m 15s\tremaining: 3m 44s\n",
      "166:\ttest: 0.7727894\tbest: 0.7727937 (165)\ttotal: 18m 21s\tremaining: 3m 37s\n",
      "167:\ttest: 0.7728782\tbest: 0.7728782 (167)\ttotal: 18m 29s\tremaining: 3m 31s\n",
      "168:\ttest: 0.7728616\tbest: 0.7728782 (167)\ttotal: 18m 36s\tremaining: 3m 24s\n",
      "169:\ttest: 0.7728585\tbest: 0.7728782 (167)\ttotal: 18m 43s\tremaining: 3m 18s\n",
      "170:\ttest: 0.7728472\tbest: 0.7728782 (167)\ttotal: 18m 50s\tremaining: 3m 11s\n",
      "171:\ttest: 0.7728362\tbest: 0.7728782 (167)\ttotal: 18m 58s\tremaining: 3m 5s\n",
      "172:\ttest: 0.7728567\tbest: 0.7728782 (167)\ttotal: 19m 4s\tremaining: 2m 58s\n",
      "173:\ttest: 0.7728636\tbest: 0.7728782 (167)\ttotal: 19m 12s\tremaining: 2m 52s\n",
      "174:\ttest: 0.7728829\tbest: 0.7728829 (174)\ttotal: 19m 18s\tremaining: 2m 45s\n",
      "175:\ttest: 0.7729638\tbest: 0.7729638 (175)\ttotal: 19m 26s\tremaining: 2m 39s\n",
      "176:\ttest: 0.7729678\tbest: 0.7729678 (176)\ttotal: 19m 32s\tremaining: 2m 32s\n",
      "177:\ttest: 0.7729715\tbest: 0.7729715 (177)\ttotal: 19m 39s\tremaining: 2m 25s\n",
      "178:\ttest: 0.7730053\tbest: 0.7730053 (178)\ttotal: 19m 46s\tremaining: 2m 19s\n",
      "179:\ttest: 0.7729968\tbest: 0.7730053 (178)\ttotal: 19m 52s\tremaining: 2m 12s\n",
      "180:\ttest: 0.7729936\tbest: 0.7730053 (178)\ttotal: 19m 59s\tremaining: 2m 5s\n",
      "181:\ttest: 0.7729838\tbest: 0.7730053 (178)\ttotal: 20m 7s\tremaining: 1m 59s\n",
      "182:\ttest: 0.7729973\tbest: 0.7730053 (178)\ttotal: 20m 14s\tremaining: 1m 52s\n",
      "183:\ttest: 0.7729814\tbest: 0.7730053 (178)\ttotal: 20m 20s\tremaining: 1m 46s\n",
      "184:\ttest: 0.7729531\tbest: 0.7730053 (178)\ttotal: 20m 28s\tremaining: 1m 39s\n",
      "185:\ttest: 0.7729897\tbest: 0.7730053 (178)\ttotal: 20m 35s\tremaining: 1m 32s\n",
      "186:\ttest: 0.7729952\tbest: 0.7730053 (178)\ttotal: 20m 42s\tremaining: 1m 26s\n",
      "187:\ttest: 0.7729852\tbest: 0.7730053 (178)\ttotal: 20m 48s\tremaining: 1m 19s\n",
      "188:\ttest: 0.7729934\tbest: 0.7730053 (178)\ttotal: 20m 55s\tremaining: 1m 13s\n",
      "189:\ttest: 0.7730111\tbest: 0.7730111 (189)\ttotal: 21m 2s\tremaining: 1m 6s\n",
      "190:\ttest: 0.7730353\tbest: 0.7730353 (190)\ttotal: 21m 9s\tremaining: 59.8s\n",
      "191:\ttest: 0.7730197\tbest: 0.7730353 (190)\ttotal: 21m 15s\tremaining: 53.1s\n",
      "192:\ttest: 0.7729855\tbest: 0.7730353 (190)\ttotal: 21m 22s\tremaining: 46.5s\n",
      "193:\ttest: 0.7729533\tbest: 0.7730353 (190)\ttotal: 21m 29s\tremaining: 39.9s\n",
      "194:\ttest: 0.7729309\tbest: 0.7730353 (190)\ttotal: 21m 36s\tremaining: 33.2s\n",
      "195:\ttest: 0.7729165\tbest: 0.7730353 (190)\ttotal: 21m 43s\tremaining: 26.6s\n",
      "196:\ttest: 0.7729140\tbest: 0.7730353 (190)\ttotal: 21m 50s\tremaining: 19.9s\n",
      "197:\ttest: 0.7729046\tbest: 0.7730353 (190)\ttotal: 21m 58s\tremaining: 13.3s\n",
      "198:\ttest: 0.7729336\tbest: 0.7730353 (190)\ttotal: 22m 6s\tremaining: 6.67s\n",
      "199:\ttest: 0.7729298\tbest: 0.7730353 (190)\ttotal: 22m 13s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7730352828\n",
      "bestIteration = 190\n",
      "\n",
      "Shrink model to first 191 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f2519af9ef0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_train, y_train_train,\n",
    "    cat_features=categorical_features_indices,\n",
    "    eval_set=(X_train_val, y_train_val),\n",
    "    logging_level='Verbose'  # you can uncomment this for text output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "199:\ttest: 0.7686368\tbest: 0.7686409 (198)\ttotal: 14m 41s\tremaining: 0us (nlp, lr=0.31)\n",
    "199:\ttest: 0.7686109\tbest: 0.7686109 (199)\ttotal: 14m 17s\tremaining: 0us (nlp, lr=0.31, 9 variables dropped)\n",
    "199:\ttest: 0.7729298\tbest: 0.7730353 (190)\ttotal: 22m 13s\tremaining: 0us (nlp, lr=0.31, 6 variables dropped, depth=8)\n",
    "199:\ttest: 0.7576144\tbest: 0.7576257 (197)\ttotal: 15m 42s\tremaining: 0us(nlp, lr=0.31, weighted, one_hot=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances=model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. RESOURCE_ID (27.207315)\n",
      "2. INCIDENT_TYPE_ID (10.336058)\n",
      "3. MODELE_CODE (8.156044)\n",
      "4. L2_ORGANISATION_ID (6.504438)\n",
      "5. COMMENTAIRE_BI_common (4.962030)\n",
      "6. nb_char_commentaire (4.617165)\n",
      "7. mois_intervention (3.927007)\n",
      "8. GRAVITE (3.428271)\n",
      "9. duree_avant_intervention (3.302414)\n",
      "10. FORMULE (2.948463)\n",
      "11. TYPE_BI (2.159771)\n",
      "12. MILLESIME (2.098388)\n",
      "13. PRIX_FACTURE (1.477682)\n",
      "14. STS_CODE (1.384772)\n",
      "15. STOP_PHONING (1.343261)\n",
      "16. age_installation (1.334129)\n",
      "17. MARQUE_LIB (1.186078)\n",
      "18. ORIGINE_INCIDENT (1.149478)\n",
      "19. temps_jusqua_fin_contrat (1.136788)\n",
      "20. NATURE_CODE (1.045200)\n",
      "21. CODE_FONCTION (1.039710)\n",
      "22. AUTEUR_INCIDENT (1.012526)\n",
      "23. nb_mots_commentaire (0.996839)\n",
      "24. NB_PASSAGE (0.900538)\n",
      "25. TYPE_OCC (0.691217)\n",
      "26. mois_appel (0.586437)\n",
      "27. OPTION (0.528086)\n",
      "28. joursemaine_intervention (0.462390)\n",
      "29. CONTRAT_TARIF (0.455775)\n",
      "30. POINTS_FIDEL (0.423038)\n",
      "31. L1_ORGANISATION_ID (0.379163)\n",
      "32. nc_5 (0.346799)\n",
      "33. temps_depuis_maj_contrat (0.333463)\n",
      "34. CODE_GEN_EQUIPEMENT (0.325024)\n",
      "35. temps_depuis_debut_contrat (0.264092)\n",
      "36. jour_intervention (0.200193)\n",
      "37. PROBLEM_CODE (0.193465)\n",
      "38. CODE_EAU_CHAUDE (0.146839)\n",
      "39. RACHAT_CODE (0.140093)\n",
      "40. has_number_commentaire (0.120224)\n",
      "41. nc_3 (0.116504)\n",
      "42. jour_appel (0.115029)\n",
      "43. PAYS (0.110434)\n",
      "44. nc_2 (0.095962)\n",
      "45. CODE_SPECIFICATION (0.080436)\n",
      "46. CODE_INSTALLATION (0.073162)\n",
      "47. CODE_ENERGIE (0.069277)\n",
      "48. joursemaine_appel (0.043406)\n",
      "49. USAGE_LOCAL (0.030023)\n",
      "50. nc_4 (0.015104)\n",
      "51. is_empty_commentaire (0.000000)\n",
      "52. duree_prevue (0.000000)\n",
      "53. nc_1 (0.000000)\n"
     ]
    }
   ],
   "source": [
    "indices = np.argsort(model.feature_importances_)[::-1]\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(train.shape[1]):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, train.columns[indices[f]], model.feature_importances_[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(train.shape[1]), importances[indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xticks(range(train.shape[1]), indices)\n",
    "plt.xlim([-1, train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = train.select_dtypes(include=['category', 'bool', 'object']).columns\n",
    "categorical_features_indices = [train.columns.get_loc(cat) for cat in categoricals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'cb__cat_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-926cef97b7f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"roc_auc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb__cat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'cb__cat_features'"
     ]
    }
   ],
   "source": [
    "#what to do with cat features\n",
    "params = {'depth': [4, 7, 10],\n",
    "          'learning_rate' : [0.20, 0.31, 0.40],\n",
    "         'l2_leaf_reg': [1, 4, 9],\n",
    "         'iterations': [300]}\n",
    "cb = CatBoostClassifier()\n",
    "cb_model = GridSearchCV(cb, params, scoring=\"roc_auc\")\n",
    "cb_model.fit(train, y_train, cb__cat_features=categorical_features_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_objective(params):\n",
    "    model = CatBoostClassifier(\n",
    "        l2_leaf_reg=int(params['l2_leaf_reg']),\n",
    "        learning_rate=params['learning_rate'],\n",
    "        iterations=int(params['iterations']),\n",
    "        border_count=int(params['border_count']),\n",
    "        eval_metric='AUC',\n",
    "        random_seed=42,\n",
    "        logging_level='Silent'\n",
    "        #od_type='Iter',\n",
    "        #od_wait=40\n",
    "    )\n",
    "    \n",
    "    cv_data = cv(\n",
    "        Pool(train, y_train, cat_features=categorical_features_indices),\n",
    "        model.get_params(),\n",
    "        fold_count=3\n",
    "    )\n",
    "    best_AUC = np.max(cv_data['test-AUC-mean'])\n",
    "    print(params, 'best_AUC: ', best_AUC)\n",
    "    \n",
    "    return 1 - best_AUC # as hyperopt minimises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param space example for xgboost\n",
    "#    space = {\n",
    "#             'n_estimators' : hp.quniform('n_estimators', 100, 1000, 1),\n",
    "#             'eta' : hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "#             'max_depth' : hp.quniform('max_depth', 1, 13, 1),\n",
    "#             'min_child_weight' : hp.quniform('min_child_weight', 1, 6, 1),\n",
    "#             'subsample' : hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "#             'gamma' : hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "#             'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "#             'num_class' : 9,\n",
    "#             'eval_metric': 'mlogloss',\n",
    "#             'objective': 'multi:softprob',\n",
    "#             'nthread' : 6,\n",
    "#             'silent' : 1\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'border_count': 213, 'depth': 7, 'iterations': 693.0, 'l2_leaf_reg': 11.47871028241772, 'learning_rate': 0.6096210638782021} best_AUC:  0.767539056284941\n",
      "{'border_count': 213, 'depth': 7, 'iterations': 526.0, 'l2_leaf_reg': 11.47871028241772, 'learning_rate': 0.701085638831484} best_AUC:  0.767228088670764\n",
      "{'border_count': 213, 'depth': 7, 'iterations': 822.0, 'l2_leaf_reg': 11.47871028241772, 'learning_rate': 0.7947626751796161} best_AUC:  0.7647414699770261\n",
      "{'border_count': 213, 'depth': 7, 'iterations': 775.0, 'l2_leaf_reg': 11.47871028241772, 'learning_rate': 0.571434077994127} best_AUC:  0.7686875566115616\n",
      "{'border_count': 213, 'depth': 7, 'iterations': 516.0, 'l2_leaf_reg': 11.47871028241772, 'learning_rate': 0.4938304425560929} best_AUC:  0.7680238623609622\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-70e5c5dc3dcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mrstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             return_argmin=return_argmin)\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     verbose=verbose)\n\u001b[1;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-115d4f7d3c4b>\u001b[0m in \u001b[0;36mhyperopt_objective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mfold_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m     \u001b[0mbest_AUC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test-AUC-mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(pool, params, dtrain, iterations, num_boost_round, fold_count, nfold, inverted, partition_random_seed, seed, shuffle, logging_level, stratified, as_pandas, metric_period, verbose, verbose_eval, plot, early_stopping_rounds)\u001b[0m\n\u001b[1;32m   2733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2734\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2735\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition_random_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._cv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._cv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "params_space = {\n",
    "    #'l2_leaf_reg': hyperopt.hp.loguniform('l2_leaf_reg', -1, np.log(50)),\n",
    "    'l2_leaf_reg': hyperopt.hp.choice('l2_leaf_reg', [11.47871028241772]),\n",
    "    'learning_rate': hyperopt.hp.uniform('learning_rate', 1e-1, 8e-1),\n",
    "     #'learning_rate': hyperopt.hp.choice('learning_rate', [0.31]),\n",
    "    'iterations': hyperopt.hp.quniform('iterations', 250, 1000, 1),\n",
    "    #'iterations': hyperopt.hp.choice('iterations', [250]),\n",
    "    #'depth': hyperopt.hp.quniform('depth', 3, 9, 1),\n",
    "    'depth': hyperopt.hp.choice('depth', [7]),\n",
    "#    'ctr_border_count': hyperopt.hp.quniform('ctr_border_count', 32, 255, 1),\n",
    "    #'border_count': hyperopt.hp.quniform('border_count', 16, 255, 1)\n",
    "    'border_count': hyperopt.hp.choice('border_count', [213])\n",
    "}\n",
    "\n",
    "trials = hyperopt.Trials()\n",
    "\n",
    "best = hyperopt.fmin(\n",
    "    hyperopt_objective,\n",
    "    space=params_space,\n",
    "    algo=hyperopt.tpe.suggest,\n",
    "    max_evals=8,\n",
    "    trials=trials,\n",
    "    rstate=RandomState(123)\n",
    "    \n",
    ")\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#round 1\n",
    "{'depth': 7.0, 'l2_leaf_reg': 6.687638927479829} best_AUC:  0.764339203919555\n",
    "{'depth': 8.0, 'l2_leaf_reg': 2.238434810070511} best_AUC:  0.7641940842160905\n",
    "{'depth': 9.0, 'l2_leaf_reg': 15.61615505112418} best_AUC:  0.7656179177534072\n",
    "{'depth': 7.0, 'l2_leaf_reg': 11.47871028241772} best_AUC:  0.766724797438951\n",
    "{'depth': 6.0, 'l2_leaf_reg': 2.0946141383866816} best_AUC:  0.7641940842160905\n",
    "{'depth': 5.0, 'l2_leaf_reg': 3.409700409045487} best_AUC:  0.7656396435014416\n",
    "{'l2_leaf_reg': 11.47871028241772, 'learning_rate': 7.0}\n",
    "\n",
    "#round 2\n",
    "{'border_count': 199.0, 'depth': 7, 'iterations': 250, 'l2_leaf_reg': 11.47871028241772, 'learning_rate': 0.31} best_AUC:  0.7654693707749893\n",
    "{'border_count': 213.0, 'depth': 7, 'iterations': 250, 'l2_leaf_reg': 11.47871028241772, 'learning_rate': 0.31} best_AUC:  0.7662068818039395\n",
    "{'border_count': 105.0, 'depth': 8, 'iterations': 250, 'l2_leaf_reg': 11.47871028241772, 'learning_rate': 0.31} best_AUC:  0.7639026943327258\n",
    "{'border_count': 238.0, 'depth': 7, 'iterations': 250, 'l2_leaf_reg': 11.47871028241772, 'learning_rate': 0.31} best_AUC:  0.764574925126635\n",
    "{'border_count': 22.0, 'depth': 8, 'iterations': 250, 'l2_leaf_reg': 11.47871028241772, 'learning_rate': 0.31} best_AUC:  0.7643064612539859\n",
    "{'border_count': 103.0, 'depth': 8, 'iterations': 250, 'l2_leaf_reg': 11.47871028241772, 'learning_rate': 0.31} best_AUC:  0.7632638136706521\n",
    "{'border_count': 225.0, 'depth': 8, 'iterations': 250, 'l2_leaf_reg': 11.47871028241772, 'learning_rate': 0.31} best_AUC:  0.7653002122083675\n",
    "{'border_count': 212.0, 'depth': 8, 'iterations': 250, 'l2_leaf_reg': 11.47871028241772, 'learning_rate': 0.31} best_AUC:  0.7649391813119792\n",
    "{'border_count': 85.0, 'depth': 8, 'iterations': 250, 'l2_leaf_reg': 11.47871028241772, 'learning_rate': 0.31} best_AUC:  0.7649657537494025\n",
    "{'border_count': 251.0, 'depth': 8, 'iterations': 250, 'l2_leaf_reg': 11.47871028241772, 'learning_rate': 0.31} best_AUC:  0.7649243873489558\n",
    "{'border_count': 213.0, 'depth': 0, 'iterations': 0, 'l2_leaf_reg': 0, 'learning_rate': 0}\n",
    "\n",
    "#round 3\n",
    "{'border_count': 213, 'depth': 7, 'iterations': 693.0, 'l2_leaf_reg': 11.47871028241772, 'learning_rate': 0.6096210638782021} best_AUC:  0.767539056284941\n",
    "{'border_count': 213, 'depth': 7, 'iterations': 526.0, 'l2_leaf_reg': 11.47871028241772, 'learning_rate': 0.701085638831484} best_AUC:  0.767228088670764\n",
    "{'border_count': 213, 'depth': 7, 'iterations': 822.0, 'l2_leaf_reg': 11.47871028241772, 'learning_rate': 0.7947626751796161} best_AUC:  0.7647414699770261\n",
    "{'border_count': 213, 'depth': 7, 'iterations': 775.0, 'l2_leaf_reg': 11.47871028241772, 'learning_rate': 0.571434077994127} best_AUC:  0.7686875566115616\n",
    "{'border_count': 213, 'depth': 7, 'iterations': 516.0, 'l2_leaf_reg': 11.47871028241772, 'learning_rate': 0.4938304425560929} best_AUC:  0.7680238623609622\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check quality to expect\n",
    "model = CatBoostClassifier(\n",
    "    l2_leaf_reg=int(best['l2_leaf_reg']),\n",
    "    learning_rate=best['learning_rate'],\n",
    "    iterations=500,\n",
    "    eval_metric='AUC',\n",
    "    random_seed=42,\n",
    "    logging_level='Silent'\n",
    ")\n",
    "cv_data = cv(Pool(X, y, cat_features=categorical_features_indices), model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precise validation AUC score: {}'.format(np.max(cv_data['test-AUC-mean'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = train.select_dtypes(include=['category', 'bool', 'object']).columns\n",
    "categorical_features_indices = [train.columns.get_loc(cat) for cat in categoricals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'border_count': 213, \n",
    "          'depth': 7, \n",
    "          'iterations': 500.0, \n",
    "          'l2_leaf_reg': 11.47871028241772, \n",
    "          'learning_rate': 0.4938304425560929}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 5.78s\tremaining: 48m 4s\n",
      "1:\ttotal: 11.4s\tremaining: 47m 15s\n",
      "2:\ttotal: 16.1s\tremaining: 44m 30s\n",
      "3:\ttotal: 21s\tremaining: 43m 27s\n",
      "4:\ttotal: 27.4s\tremaining: 45m 13s\n",
      "5:\ttotal: 34.3s\tremaining: 47m\n",
      "6:\ttotal: 40.3s\tremaining: 47m 16s\n",
      "7:\ttotal: 46.4s\tremaining: 47m 35s\n",
      "8:\ttotal: 51.4s\tremaining: 46m 43s\n",
      "9:\ttotal: 58.2s\tremaining: 47m 30s\n",
      "10:\ttotal: 1m 3s\tremaining: 47m 3s\n",
      "11:\ttotal: 1m 9s\tremaining: 47m 3s\n",
      "12:\ttotal: 1m 14s\tremaining: 46m 43s\n",
      "13:\ttotal: 1m 21s\tremaining: 47m 20s\n",
      "14:\ttotal: 1m 27s\tremaining: 47m 12s\n",
      "15:\ttotal: 1m 33s\tremaining: 47m 2s\n",
      "16:\ttotal: 1m 40s\tremaining: 47m 21s\n",
      "17:\ttotal: 1m 47s\tremaining: 48m 1s\n",
      "18:\ttotal: 1m 53s\tremaining: 47m 50s\n",
      "19:\ttotal: 1m 58s\tremaining: 47m 15s\n",
      "20:\ttotal: 2m 4s\tremaining: 47m 15s\n",
      "21:\ttotal: 2m 12s\tremaining: 47m 49s\n",
      "22:\ttotal: 2m 17s\tremaining: 47m 37s\n",
      "23:\ttotal: 2m 23s\tremaining: 47m 30s\n",
      "24:\ttotal: 2m 29s\tremaining: 47m 21s\n",
      "25:\ttotal: 2m 36s\tremaining: 47m 41s\n",
      "26:\ttotal: 2m 42s\tremaining: 47m 29s\n",
      "27:\ttotal: 2m 50s\tremaining: 47m 56s\n",
      "28:\ttotal: 2m 56s\tremaining: 47m 47s\n",
      "29:\ttotal: 3m 3s\tremaining: 47m 54s\n",
      "30:\ttotal: 3m 10s\tremaining: 48m 3s\n",
      "31:\ttotal: 3m 16s\tremaining: 47m 51s\n",
      "32:\ttotal: 3m 22s\tremaining: 47m 39s\n",
      "33:\ttotal: 3m 29s\tremaining: 47m 53s\n",
      "34:\ttotal: 3m 35s\tremaining: 47m 43s\n",
      "35:\ttotal: 3m 42s\tremaining: 47m 52s\n",
      "36:\ttotal: 3m 48s\tremaining: 47m 44s\n",
      "37:\ttotal: 3m 55s\tremaining: 47m 38s\n",
      "38:\ttotal: 4m\tremaining: 47m 17s\n",
      "39:\ttotal: 4m 5s\tremaining: 47m 7s\n",
      "40:\ttotal: 4m 11s\tremaining: 46m 53s\n",
      "41:\ttotal: 4m 17s\tremaining: 46m 45s\n",
      "42:\ttotal: 4m 22s\tremaining: 46m 25s\n",
      "43:\ttotal: 4m 28s\tremaining: 46m 20s\n",
      "44:\ttotal: 4m 33s\tremaining: 46m 6s\n",
      "45:\ttotal: 4m 39s\tremaining: 46m 2s\n",
      "46:\ttotal: 4m 45s\tremaining: 45m 56s\n",
      "47:\ttotal: 4m 51s\tremaining: 45m 46s\n",
      "48:\ttotal: 4m 57s\tremaining: 45m 38s\n",
      "49:\ttotal: 5m 2s\tremaining: 45m 26s\n",
      "50:\ttotal: 5m 8s\tremaining: 45m 17s\n",
      "51:\ttotal: 5m 13s\tremaining: 45m 4s\n",
      "52:\ttotal: 5m 18s\tremaining: 44m 49s\n",
      "53:\ttotal: 5m 23s\tremaining: 44m 28s\n",
      "54:\ttotal: 5m 28s\tremaining: 44m 18s\n",
      "55:\ttotal: 5m 33s\tremaining: 44m 5s\n",
      "56:\ttotal: 5m 40s\tremaining: 44m 3s\n",
      "57:\ttotal: 5m 46s\tremaining: 43m 59s\n",
      "58:\ttotal: 5m 52s\tremaining: 43m 53s\n",
      "59:\ttotal: 5m 58s\tremaining: 43m 49s\n",
      "60:\ttotal: 6m 4s\tremaining: 43m 42s\n",
      "61:\ttotal: 6m 10s\tremaining: 43m 37s\n",
      "62:\ttotal: 6m 17s\tremaining: 43m 38s\n",
      "63:\ttotal: 6m 23s\tremaining: 43m 34s\n",
      "64:\ttotal: 6m 29s\tremaining: 43m 24s\n",
      "65:\ttotal: 6m 34s\tremaining: 43m 11s\n",
      "66:\ttotal: 6m 39s\tremaining: 43m 3s\n",
      "67:\ttotal: 6m 44s\tremaining: 42m 51s\n",
      "68:\ttotal: 6m 51s\tremaining: 42m 47s\n",
      "69:\ttotal: 6m 57s\tremaining: 42m 43s\n",
      "70:\ttotal: 7m 2s\tremaining: 42m 35s\n",
      "71:\ttotal: 7m 9s\tremaining: 42m 33s\n",
      "72:\ttotal: 7m 14s\tremaining: 42m 19s\n",
      "73:\ttotal: 7m 20s\tremaining: 42m 13s\n",
      "74:\ttotal: 7m 27s\tremaining: 42m 13s\n",
      "75:\ttotal: 7m 33s\tremaining: 42m 8s\n",
      "76:\ttotal: 7m 39s\tremaining: 42m 1s\n",
      "77:\ttotal: 7m 45s\tremaining: 41m 58s\n",
      "78:\ttotal: 7m 50s\tremaining: 41m 48s\n",
      "79:\ttotal: 7m 56s\tremaining: 41m 43s\n",
      "80:\ttotal: 8m 2s\tremaining: 41m 38s\n",
      "81:\ttotal: 8m 10s\tremaining: 41m 39s\n",
      "82:\ttotal: 8m 14s\tremaining: 41m 26s\n",
      "83:\ttotal: 8m 20s\tremaining: 41m 18s\n",
      "84:\ttotal: 8m 26s\tremaining: 41m 10s\n",
      "85:\ttotal: 8m 31s\tremaining: 41m 4s\n",
      "86:\ttotal: 8m 36s\tremaining: 40m 54s\n",
      "87:\ttotal: 8m 43s\tremaining: 40m 48s\n",
      "88:\ttotal: 8m 48s\tremaining: 40m 41s\n",
      "89:\ttotal: 8m 54s\tremaining: 40m 35s\n",
      "90:\ttotal: 9m\tremaining: 40m 29s\n",
      "91:\ttotal: 9m 5s\tremaining: 40m 20s\n",
      "92:\ttotal: 9m 14s\tremaining: 40m 24s\n",
      "93:\ttotal: 9m 20s\tremaining: 40m 19s\n",
      "94:\ttotal: 9m 26s\tremaining: 40m 13s\n",
      "95:\ttotal: 9m 32s\tremaining: 40m 8s\n",
      "96:\ttotal: 9m 38s\tremaining: 40m 3s\n",
      "97:\ttotal: 9m 44s\tremaining: 39m 57s\n",
      "98:\ttotal: 9m 50s\tremaining: 39m 52s\n",
      "99:\ttotal: 9m 57s\tremaining: 39m 48s\n",
      "100:\ttotal: 10m 2s\tremaining: 39m 39s\n",
      "101:\ttotal: 10m 7s\tremaining: 39m 28s\n",
      "102:\ttotal: 10m 14s\tremaining: 39m 27s\n",
      "103:\ttotal: 10m 19s\tremaining: 39m 18s\n",
      "104:\ttotal: 10m 26s\tremaining: 39m 17s\n",
      "105:\ttotal: 10m 32s\tremaining: 39m 12s\n",
      "106:\ttotal: 10m 38s\tremaining: 39m 4s\n",
      "107:\ttotal: 10m 43s\tremaining: 38m 55s\n",
      "108:\ttotal: 10m 50s\tremaining: 38m 52s\n",
      "109:\ttotal: 10m 56s\tremaining: 38m 46s\n",
      "110:\ttotal: 11m 3s\tremaining: 38m 44s\n",
      "111:\ttotal: 11m 10s\tremaining: 38m 43s\n",
      "112:\ttotal: 11m 16s\tremaining: 38m 38s\n",
      "113:\ttotal: 11m 23s\tremaining: 38m 33s\n",
      "114:\ttotal: 11m 30s\tremaining: 38m 31s\n",
      "115:\ttotal: 11m 36s\tremaining: 38m 26s\n",
      "116:\ttotal: 11m 43s\tremaining: 38m 23s\n",
      "117:\ttotal: 11m 50s\tremaining: 38m 19s\n",
      "118:\ttotal: 11m 57s\tremaining: 38m 18s\n",
      "119:\ttotal: 12m 4s\tremaining: 38m 13s\n",
      "120:\ttotal: 12m 9s\tremaining: 38m 5s\n",
      "121:\ttotal: 12m 17s\tremaining: 38m 4s\n",
      "122:\ttotal: 12m 24s\tremaining: 38m 2s\n",
      "123:\ttotal: 12m 30s\tremaining: 37m 54s\n",
      "124:\ttotal: 12m 37s\tremaining: 37m 53s\n",
      "125:\ttotal: 12m 44s\tremaining: 37m 48s\n",
      "126:\ttotal: 12m 51s\tremaining: 37m 45s\n",
      "127:\ttotal: 12m 58s\tremaining: 37m 42s\n",
      "128:\ttotal: 13m 4s\tremaining: 37m 37s\n",
      "129:\ttotal: 13m 11s\tremaining: 37m 33s\n",
      "130:\ttotal: 13m 17s\tremaining: 37m 27s\n",
      "131:\ttotal: 13m 24s\tremaining: 37m 22s\n",
      "132:\ttotal: 13m 30s\tremaining: 37m 16s\n",
      "133:\ttotal: 13m 37s\tremaining: 37m 11s\n",
      "134:\ttotal: 13m 42s\tremaining: 37m 4s\n",
      "135:\ttotal: 13m 48s\tremaining: 36m 58s\n",
      "136:\ttotal: 13m 55s\tremaining: 36m 52s\n",
      "137:\ttotal: 14m\tremaining: 36m 45s\n",
      "138:\ttotal: 14m 6s\tremaining: 36m 37s\n",
      "139:\ttotal: 14m 11s\tremaining: 36m 29s\n",
      "140:\ttotal: 14m 16s\tremaining: 36m 19s\n",
      "141:\ttotal: 14m 21s\tremaining: 36m 12s\n",
      "142:\ttotal: 14m 27s\tremaining: 36m 5s\n",
      "143:\ttotal: 14m 33s\tremaining: 35m 58s\n",
      "144:\ttotal: 14m 38s\tremaining: 35m 50s\n",
      "145:\ttotal: 14m 44s\tremaining: 35m 44s\n",
      "146:\ttotal: 14m 50s\tremaining: 35m 38s\n",
      "147:\ttotal: 14m 56s\tremaining: 35m 32s\n",
      "148:\ttotal: 15m 3s\tremaining: 35m 27s\n",
      "149:\ttotal: 15m 8s\tremaining: 35m 19s\n",
      "150:\ttotal: 15m 13s\tremaining: 35m 11s\n",
      "151:\ttotal: 15m 19s\tremaining: 35m 4s\n",
      "152:\ttotal: 15m 25s\tremaining: 34m 58s\n",
      "153:\ttotal: 15m 30s\tremaining: 34m 51s\n",
      "154:\ttotal: 15m 36s\tremaining: 34m 45s\n",
      "155:\ttotal: 15m 42s\tremaining: 34m 38s\n",
      "156:\ttotal: 15m 48s\tremaining: 34m 31s\n",
      "157:\ttotal: 15m 54s\tremaining: 34m 26s\n",
      "158:\ttotal: 16m\tremaining: 34m 19s\n",
      "159:\ttotal: 16m 6s\tremaining: 34m 13s\n",
      "160:\ttotal: 16m 12s\tremaining: 34m 7s\n",
      "161:\ttotal: 16m 18s\tremaining: 34m 2s\n",
      "162:\ttotal: 16m 24s\tremaining: 33m 55s\n",
      "163:\ttotal: 16m 29s\tremaining: 33m 48s\n",
      "164:\ttotal: 16m 35s\tremaining: 33m 40s\n",
      "165:\ttotal: 16m 40s\tremaining: 33m 33s\n",
      "166:\ttotal: 16m 48s\tremaining: 33m 30s\n",
      "167:\ttotal: 16m 54s\tremaining: 33m 24s\n",
      "168:\ttotal: 17m\tremaining: 33m 18s\n",
      "169:\ttotal: 17m 7s\tremaining: 33m 14s\n",
      "170:\ttotal: 17m 12s\tremaining: 33m 7s\n",
      "171:\ttotal: 17m 18s\tremaining: 33m\n",
      "172:\ttotal: 17m 24s\tremaining: 32m 55s\n",
      "173:\ttotal: 17m 30s\tremaining: 32m 48s\n",
      "174:\ttotal: 17m 35s\tremaining: 32m 40s\n",
      "175:\ttotal: 17m 41s\tremaining: 32m 33s\n",
      "176:\ttotal: 17m 46s\tremaining: 32m 25s\n",
      "177:\ttotal: 17m 51s\tremaining: 32m 17s\n",
      "178:\ttotal: 17m 57s\tremaining: 32m 11s\n",
      "179:\ttotal: 18m 3s\tremaining: 32m 5s\n",
      "180:\ttotal: 18m 8s\tremaining: 31m 58s\n",
      "181:\ttotal: 18m 14s\tremaining: 31m 51s\n",
      "182:\ttotal: 18m 19s\tremaining: 31m 45s\n",
      "183:\ttotal: 18m 25s\tremaining: 31m 38s\n",
      "184:\ttotal: 18m 32s\tremaining: 31m 34s\n",
      "185:\ttotal: 18m 39s\tremaining: 31m 29s\n",
      "186:\ttotal: 18m 45s\tremaining: 31m 24s\n",
      "187:\ttotal: 18m 52s\tremaining: 31m 19s\n",
      "188:\ttotal: 18m 58s\tremaining: 31m 13s\n",
      "189:\ttotal: 19m 4s\tremaining: 31m 7s\n",
      "190:\ttotal: 19m 10s\tremaining: 31m\n",
      "191:\ttotal: 19m 17s\tremaining: 30m 57s\n",
      "192:\ttotal: 19m 24s\tremaining: 30m 52s\n",
      "193:\ttotal: 19m 31s\tremaining: 30m 47s\n",
      "194:\ttotal: 19m 38s\tremaining: 30m 42s\n",
      "195:\ttotal: 19m 44s\tremaining: 30m 36s\n",
      "196:\ttotal: 19m 51s\tremaining: 30m 32s\n",
      "197:\ttotal: 19m 58s\tremaining: 30m 27s\n",
      "198:\ttotal: 20m 5s\tremaining: 30m 22s\n",
      "199:\ttotal: 20m 11s\tremaining: 30m 17s\n",
      "200:\ttotal: 20m 17s\tremaining: 30m 11s\n",
      "201:\ttotal: 20m 23s\tremaining: 30m 4s\n",
      "202:\ttotal: 20m 30s\tremaining: 30m\n",
      "203:\ttotal: 20m 37s\tremaining: 29m 55s\n",
      "204:\ttotal: 20m 43s\tremaining: 29m 49s\n",
      "205:\ttotal: 20m 50s\tremaining: 29m 44s\n",
      "206:\ttotal: 20m 57s\tremaining: 29m 39s\n",
      "207:\ttotal: 21m 3s\tremaining: 29m 34s\n",
      "208:\ttotal: 21m 11s\tremaining: 29m 30s\n",
      "209:\ttotal: 21m 17s\tremaining: 29m 24s\n",
      "210:\ttotal: 21m 24s\tremaining: 29m 19s\n",
      "211:\ttotal: 21m 31s\tremaining: 29m 14s\n",
      "212:\ttotal: 21m 39s\tremaining: 29m 11s\n",
      "213:\ttotal: 21m 46s\tremaining: 29m 6s\n",
      "214:\ttotal: 21m 54s\tremaining: 29m 2s\n",
      "215:\ttotal: 21m 59s\tremaining: 28m 55s\n",
      "216:\ttotal: 22m 6s\tremaining: 28m 49s\n",
      "217:\ttotal: 22m 13s\tremaining: 28m 44s\n",
      "218:\ttotal: 22m 19s\tremaining: 28m 38s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219:\ttotal: 22m 26s\tremaining: 28m 33s\n",
      "220:\ttotal: 22m 32s\tremaining: 28m 27s\n",
      "221:\ttotal: 22m 38s\tremaining: 28m 21s\n",
      "222:\ttotal: 22m 45s\tremaining: 28m 16s\n",
      "223:\ttotal: 22m 53s\tremaining: 28m 12s\n",
      "224:\ttotal: 23m\tremaining: 28m 7s\n",
      "225:\ttotal: 23m 7s\tremaining: 28m 1s\n",
      "226:\ttotal: 23m 13s\tremaining: 27m 55s\n",
      "227:\ttotal: 23m 20s\tremaining: 27m 50s\n",
      "228:\ttotal: 23m 27s\tremaining: 27m 45s\n",
      "229:\ttotal: 23m 33s\tremaining: 27m 38s\n",
      "230:\ttotal: 23m 39s\tremaining: 27m 33s\n",
      "231:\ttotal: 23m 46s\tremaining: 27m 28s\n",
      "232:\ttotal: 23m 55s\tremaining: 27m 24s\n",
      "233:\ttotal: 24m 1s\tremaining: 27m 18s\n",
      "234:\ttotal: 24m 8s\tremaining: 27m 13s\n",
      "235:\ttotal: 24m 15s\tremaining: 27m 7s\n",
      "236:\ttotal: 24m 22s\tremaining: 27m 3s\n",
      "237:\ttotal: 24m 31s\tremaining: 26m 59s\n",
      "238:\ttotal: 24m 37s\tremaining: 26m 53s\n",
      "239:\ttotal: 24m 44s\tremaining: 26m 48s\n",
      "240:\ttotal: 24m 51s\tremaining: 26m 43s\n",
      "241:\ttotal: 24m 58s\tremaining: 26m 37s\n",
      "242:\ttotal: 25m 5s\tremaining: 26m 31s\n",
      "243:\ttotal: 25m 11s\tremaining: 26m 26s\n",
      "244:\ttotal: 25m 18s\tremaining: 26m 20s\n",
      "245:\ttotal: 25m 25s\tremaining: 26m 15s\n",
      "246:\ttotal: 25m 32s\tremaining: 26m 9s\n",
      "247:\ttotal: 25m 39s\tremaining: 26m 4s\n",
      "248:\ttotal: 25m 46s\tremaining: 25m 58s\n",
      "249:\ttotal: 25m 52s\tremaining: 25m 52s\n",
      "250:\ttotal: 25m 59s\tremaining: 25m 46s\n",
      "251:\ttotal: 26m 4s\tremaining: 25m 39s\n",
      "252:\ttotal: 26m 11s\tremaining: 25m 34s\n",
      "253:\ttotal: 26m 16s\tremaining: 25m 27s\n",
      "254:\ttotal: 26m 23s\tremaining: 25m 21s\n",
      "255:\ttotal: 26m 31s\tremaining: 25m 16s\n",
      "256:\ttotal: 26m 38s\tremaining: 25m 11s\n",
      "257:\ttotal: 26m 44s\tremaining: 25m 5s\n",
      "258:\ttotal: 26m 50s\tremaining: 24m 58s\n",
      "259:\ttotal: 26m 57s\tremaining: 24m 52s\n",
      "260:\ttotal: 27m 3s\tremaining: 24m 46s\n",
      "261:\ttotal: 27m 10s\tremaining: 24m 41s\n",
      "262:\ttotal: 27m 16s\tremaining: 24m 34s\n",
      "263:\ttotal: 27m 24s\tremaining: 24m 30s\n",
      "264:\ttotal: 27m 31s\tremaining: 24m 24s\n",
      "265:\ttotal: 27m 38s\tremaining: 24m 18s\n",
      "266:\ttotal: 27m 45s\tremaining: 24m 13s\n",
      "267:\ttotal: 27m 51s\tremaining: 24m 7s\n",
      "268:\ttotal: 27m 58s\tremaining: 24m\n",
      "269:\ttotal: 28m 4s\tremaining: 23m 54s\n",
      "270:\ttotal: 28m 11s\tremaining: 23m 48s\n",
      "271:\ttotal: 28m 18s\tremaining: 23m 43s\n",
      "272:\ttotal: 28m 25s\tremaining: 23m 38s\n",
      "273:\ttotal: 28m 33s\tremaining: 23m 33s\n",
      "274:\ttotal: 28m 40s\tremaining: 23m 27s\n",
      "275:\ttotal: 28m 47s\tremaining: 23m 21s\n",
      "276:\ttotal: 28m 53s\tremaining: 23m 15s\n",
      "277:\ttotal: 28m 58s\tremaining: 23m 8s\n",
      "278:\ttotal: 29m 4s\tremaining: 23m 1s\n",
      "279:\ttotal: 29m 10s\tremaining: 22m 55s\n",
      "280:\ttotal: 29m 15s\tremaining: 22m 48s\n",
      "281:\ttotal: 29m 21s\tremaining: 22m 41s\n",
      "282:\ttotal: 29m 27s\tremaining: 22m 35s\n",
      "283:\ttotal: 29m 33s\tremaining: 22m 28s\n",
      "284:\ttotal: 29m 39s\tremaining: 22m 22s\n",
      "285:\ttotal: 29m 46s\tremaining: 22m 16s\n",
      "286:\ttotal: 29m 52s\tremaining: 22m 10s\n",
      "287:\ttotal: 29m 59s\tremaining: 22m 4s\n",
      "288:\ttotal: 30m 5s\tremaining: 21m 58s\n",
      "289:\ttotal: 30m 11s\tremaining: 21m 51s\n",
      "290:\ttotal: 30m 16s\tremaining: 21m 44s\n",
      "291:\ttotal: 30m 21s\tremaining: 21m 37s\n",
      "292:\ttotal: 30m 27s\tremaining: 21m 31s\n",
      "293:\ttotal: 30m 33s\tremaining: 21m 24s\n",
      "294:\ttotal: 30m 39s\tremaining: 21m 17s\n",
      "295:\ttotal: 30m 45s\tremaining: 21m 11s\n",
      "296:\ttotal: 30m 51s\tremaining: 21m 5s\n",
      "297:\ttotal: 30m 57s\tremaining: 20m 58s\n",
      "298:\ttotal: 31m 2s\tremaining: 20m 51s\n",
      "299:\ttotal: 31m 7s\tremaining: 20m 45s\n",
      "300:\ttotal: 31m 13s\tremaining: 20m 38s\n",
      "301:\ttotal: 31m 18s\tremaining: 20m 31s\n",
      "302:\ttotal: 31m 25s\tremaining: 20m 25s\n",
      "303:\ttotal: 31m 31s\tremaining: 20m 19s\n",
      "304:\ttotal: 31m 36s\tremaining: 20m 12s\n",
      "305:\ttotal: 31m 41s\tremaining: 20m 5s\n",
      "306:\ttotal: 31m 47s\tremaining: 19m 58s\n",
      "307:\ttotal: 31m 52s\tremaining: 19m 52s\n",
      "308:\ttotal: 31m 59s\tremaining: 19m 46s\n",
      "309:\ttotal: 32m 4s\tremaining: 19m 39s\n",
      "310:\ttotal: 32m 9s\tremaining: 19m 32s\n",
      "311:\ttotal: 32m 15s\tremaining: 19m 25s\n",
      "312:\ttotal: 32m 20s\tremaining: 19m 19s\n",
      "313:\ttotal: 32m 25s\tremaining: 19m 12s\n",
      "314:\ttotal: 32m 30s\tremaining: 19m 5s\n",
      "315:\ttotal: 32m 36s\tremaining: 18m 59s\n",
      "316:\ttotal: 32m 41s\tremaining: 18m 52s\n",
      "317:\ttotal: 32m 48s\tremaining: 18m 46s\n",
      "318:\ttotal: 32m 52s\tremaining: 18m 39s\n",
      "319:\ttotal: 32m 57s\tremaining: 18m 32s\n",
      "320:\ttotal: 33m 3s\tremaining: 18m 25s\n",
      "321:\ttotal: 33m 8s\tremaining: 18m 19s\n",
      "322:\ttotal: 33m 14s\tremaining: 18m 12s\n",
      "323:\ttotal: 33m 19s\tremaining: 18m 6s\n",
      "324:\ttotal: 33m 24s\tremaining: 17m 59s\n",
      "325:\ttotal: 33m 29s\tremaining: 17m 52s\n",
      "326:\ttotal: 33m 35s\tremaining: 17m 46s\n",
      "327:\ttotal: 33m 40s\tremaining: 17m 39s\n",
      "328:\ttotal: 33m 45s\tremaining: 17m 32s\n",
      "329:\ttotal: 33m 52s\tremaining: 17m 27s\n",
      "330:\ttotal: 33m 58s\tremaining: 17m 20s\n",
      "331:\ttotal: 34m 4s\tremaining: 17m 14s\n",
      "332:\ttotal: 34m 9s\tremaining: 17m 7s\n",
      "333:\ttotal: 34m 15s\tremaining: 17m 1s\n",
      "334:\ttotal: 34m 21s\tremaining: 16m 55s\n",
      "335:\ttotal: 34m 27s\tremaining: 16m 49s\n",
      "336:\ttotal: 34m 32s\tremaining: 16m 42s\n",
      "337:\ttotal: 34m 38s\tremaining: 16m 36s\n",
      "338:\ttotal: 34m 45s\tremaining: 16m 30s\n",
      "339:\ttotal: 34m 52s\tremaining: 16m 24s\n",
      "340:\ttotal: 34m 58s\tremaining: 16m 18s\n",
      "341:\ttotal: 35m 4s\tremaining: 16m 12s\n",
      "342:\ttotal: 35m 11s\tremaining: 16m 6s\n",
      "343:\ttotal: 35m 17s\tremaining: 16m\n",
      "344:\ttotal: 35m 24s\tremaining: 15m 54s\n",
      "345:\ttotal: 35m 30s\tremaining: 15m 48s\n",
      "346:\ttotal: 35m 36s\tremaining: 15m 41s\n",
      "347:\ttotal: 35m 42s\tremaining: 15m 35s\n",
      "348:\ttotal: 35m 48s\tremaining: 15m 29s\n",
      "349:\ttotal: 35m 56s\tremaining: 15m 24s\n",
      "350:\ttotal: 36m 2s\tremaining: 15m 18s\n",
      "351:\ttotal: 36m 8s\tremaining: 15m 11s\n",
      "352:\ttotal: 36m 14s\tremaining: 15m 5s\n",
      "353:\ttotal: 36m 19s\tremaining: 14m 59s\n",
      "354:\ttotal: 36m 26s\tremaining: 14m 53s\n",
      "355:\ttotal: 36m 33s\tremaining: 14m 47s\n",
      "356:\ttotal: 36m 39s\tremaining: 14m 41s\n",
      "357:\ttotal: 36m 45s\tremaining: 14m 34s\n",
      "358:\ttotal: 36m 51s\tremaining: 14m 28s\n",
      "359:\ttotal: 36m 57s\tremaining: 14m 22s\n",
      "360:\ttotal: 37m 3s\tremaining: 14m 16s\n",
      "361:\ttotal: 37m 9s\tremaining: 14m 9s\n",
      "362:\ttotal: 37m 14s\tremaining: 14m 3s\n",
      "363:\ttotal: 37m 20s\tremaining: 13m 57s\n",
      "364:\ttotal: 37m 26s\tremaining: 13m 50s\n",
      "365:\ttotal: 37m 32s\tremaining: 13m 44s\n",
      "366:\ttotal: 37m 38s\tremaining: 13m 38s\n",
      "367:\ttotal: 37m 45s\tremaining: 13m 32s\n",
      "368:\ttotal: 37m 49s\tremaining: 13m 25s\n",
      "369:\ttotal: 37m 56s\tremaining: 13m 19s\n",
      "370:\ttotal: 38m 3s\tremaining: 13m 13s\n",
      "371:\ttotal: 38m 9s\tremaining: 13m 7s\n",
      "372:\ttotal: 38m 15s\tremaining: 13m 1s\n",
      "373:\ttotal: 38m 22s\tremaining: 12m 55s\n",
      "374:\ttotal: 38m 29s\tremaining: 12m 49s\n",
      "375:\ttotal: 38m 33s\tremaining: 12m 43s\n",
      "376:\ttotal: 38m 39s\tremaining: 12m 36s\n",
      "377:\ttotal: 38m 45s\tremaining: 12m 30s\n",
      "378:\ttotal: 38m 53s\tremaining: 12m 25s\n",
      "379:\ttotal: 38m 58s\tremaining: 12m 18s\n",
      "380:\ttotal: 39m 5s\tremaining: 12m 12s\n",
      "381:\ttotal: 39m 11s\tremaining: 12m 6s\n",
      "382:\ttotal: 39m 16s\tremaining: 11m 59s\n",
      "383:\ttotal: 39m 22s\tremaining: 11m 53s\n",
      "384:\ttotal: 39m 29s\tremaining: 11m 47s\n",
      "385:\ttotal: 39m 34s\tremaining: 11m 41s\n",
      "386:\ttotal: 39m 40s\tremaining: 11m 35s\n",
      "387:\ttotal: 39m 47s\tremaining: 11m 29s\n",
      "388:\ttotal: 39m 53s\tremaining: 11m 23s\n",
      "389:\ttotal: 39m 59s\tremaining: 11m 16s\n",
      "390:\ttotal: 40m 5s\tremaining: 11m 10s\n",
      "391:\ttotal: 40m 10s\tremaining: 11m 4s\n",
      "392:\ttotal: 40m 16s\tremaining: 10m 57s\n",
      "393:\ttotal: 40m 21s\tremaining: 10m 51s\n",
      "394:\ttotal: 40m 28s\tremaining: 10m 45s\n",
      "395:\ttotal: 40m 34s\tremaining: 10m 39s\n",
      "396:\ttotal: 40m 40s\tremaining: 10m 33s\n",
      "397:\ttotal: 40m 46s\tremaining: 10m 26s\n",
      "398:\ttotal: 40m 51s\tremaining: 10m 20s\n",
      "399:\ttotal: 40m 57s\tremaining: 10m 14s\n",
      "400:\ttotal: 41m 3s\tremaining: 10m 8s\n",
      "401:\ttotal: 41m 10s\tremaining: 10m 2s\n",
      "402:\ttotal: 41m 15s\tremaining: 9m 55s\n",
      "403:\ttotal: 41m 20s\tremaining: 9m 49s\n",
      "404:\ttotal: 41m 26s\tremaining: 9m 43s\n",
      "405:\ttotal: 41m 31s\tremaining: 9m 36s\n",
      "406:\ttotal: 41m 37s\tremaining: 9m 30s\n",
      "407:\ttotal: 41m 42s\tremaining: 9m 24s\n",
      "408:\ttotal: 41m 48s\tremaining: 9m 18s\n",
      "409:\ttotal: 41m 53s\tremaining: 9m 11s\n",
      "410:\ttotal: 42m\tremaining: 9m 5s\n",
      "411:\ttotal: 42m 7s\tremaining: 8m 59s\n",
      "412:\ttotal: 42m 13s\tremaining: 8m 53s\n",
      "413:\ttotal: 42m 19s\tremaining: 8m 47s\n",
      "414:\ttotal: 42m 25s\tremaining: 8m 41s\n",
      "415:\ttotal: 42m 32s\tremaining: 8m 35s\n",
      "416:\ttotal: 42m 38s\tremaining: 8m 29s\n",
      "417:\ttotal: 42m 45s\tremaining: 8m 23s\n",
      "418:\ttotal: 42m 52s\tremaining: 8m 17s\n",
      "419:\ttotal: 42m 59s\tremaining: 8m 11s\n",
      "420:\ttotal: 43m 5s\tremaining: 8m 5s\n",
      "421:\ttotal: 43m 12s\tremaining: 7m 59s\n",
      "422:\ttotal: 43m 18s\tremaining: 7m 52s\n",
      "423:\ttotal: 43m 24s\tremaining: 7m 46s\n",
      "424:\ttotal: 43m 30s\tremaining: 7m 40s\n",
      "425:\ttotal: 43m 36s\tremaining: 7m 34s\n",
      "426:\ttotal: 43m 42s\tremaining: 7m 28s\n",
      "427:\ttotal: 43m 48s\tremaining: 7m 22s\n",
      "428:\ttotal: 43m 55s\tremaining: 7m 16s\n",
      "429:\ttotal: 44m 2s\tremaining: 7m 10s\n",
      "430:\ttotal: 44m 9s\tremaining: 7m 4s\n",
      "431:\ttotal: 44m 14s\tremaining: 6m 57s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432:\ttotal: 44m 21s\tremaining: 6m 51s\n",
      "433:\ttotal: 44m 28s\tremaining: 6m 45s\n",
      "434:\ttotal: 44m 33s\tremaining: 6m 39s\n",
      "435:\ttotal: 44m 39s\tremaining: 6m 33s\n",
      "436:\ttotal: 44m 45s\tremaining: 6m 27s\n",
      "437:\ttotal: 44m 51s\tremaining: 6m 20s\n",
      "438:\ttotal: 44m 56s\tremaining: 6m 14s\n",
      "439:\ttotal: 45m 3s\tremaining: 6m 8s\n",
      "440:\ttotal: 45m 11s\tremaining: 6m 2s\n",
      "441:\ttotal: 45m 17s\tremaining: 5m 56s\n",
      "442:\ttotal: 45m 24s\tremaining: 5m 50s\n",
      "443:\ttotal: 45m 30s\tremaining: 5m 44s\n",
      "444:\ttotal: 45m 36s\tremaining: 5m 38s\n",
      "445:\ttotal: 45m 42s\tremaining: 5m 32s\n",
      "446:\ttotal: 45m 49s\tremaining: 5m 25s\n",
      "447:\ttotal: 45m 56s\tremaining: 5m 19s\n",
      "448:\ttotal: 46m 2s\tremaining: 5m 13s\n",
      "449:\ttotal: 46m 9s\tremaining: 5m 7s\n",
      "450:\ttotal: 46m 16s\tremaining: 5m 1s\n",
      "451:\ttotal: 46m 23s\tremaining: 4m 55s\n",
      "452:\ttotal: 46m 30s\tremaining: 4m 49s\n",
      "453:\ttotal: 46m 37s\tremaining: 4m 43s\n",
      "454:\ttotal: 46m 43s\tremaining: 4m 37s\n",
      "455:\ttotal: 46m 50s\tremaining: 4m 31s\n",
      "456:\ttotal: 46m 56s\tremaining: 4m 25s\n",
      "457:\ttotal: 47m 2s\tremaining: 4m 18s\n",
      "458:\ttotal: 47m 9s\tremaining: 4m 12s\n",
      "459:\ttotal: 47m 15s\tremaining: 4m 6s\n",
      "460:\ttotal: 47m 21s\tremaining: 4m\n",
      "461:\ttotal: 47m 28s\tremaining: 3m 54s\n",
      "462:\ttotal: 47m 33s\tremaining: 3m 48s\n",
      "463:\ttotal: 47m 41s\tremaining: 3m 42s\n",
      "464:\ttotal: 47m 47s\tremaining: 3m 35s\n",
      "465:\ttotal: 47m 53s\tremaining: 3m 29s\n",
      "466:\ttotal: 47m 59s\tremaining: 3m 23s\n",
      "467:\ttotal: 48m 5s\tremaining: 3m 17s\n",
      "468:\ttotal: 48m 11s\tremaining: 3m 11s\n",
      "469:\ttotal: 48m 17s\tremaining: 3m 4s\n",
      "470:\ttotal: 48m 23s\tremaining: 2m 58s\n",
      "471:\ttotal: 48m 30s\tremaining: 2m 52s\n",
      "472:\ttotal: 48m 37s\tremaining: 2m 46s\n",
      "473:\ttotal: 48m 42s\tremaining: 2m 40s\n",
      "474:\ttotal: 48m 49s\tremaining: 2m 34s\n",
      "475:\ttotal: 48m 55s\tremaining: 2m 28s\n",
      "476:\ttotal: 49m 1s\tremaining: 2m 21s\n",
      "477:\ttotal: 49m 7s\tremaining: 2m 15s\n",
      "478:\ttotal: 49m 12s\tremaining: 2m 9s\n",
      "479:\ttotal: 49m 17s\tremaining: 2m 3s\n",
      "480:\ttotal: 49m 23s\tremaining: 1m 57s\n",
      "481:\ttotal: 49m 29s\tremaining: 1m 50s\n",
      "482:\ttotal: 49m 35s\tremaining: 1m 44s\n",
      "483:\ttotal: 49m 41s\tremaining: 1m 38s\n",
      "484:\ttotal: 49m 47s\tremaining: 1m 32s\n",
      "485:\ttotal: 49m 53s\tremaining: 1m 26s\n",
      "486:\ttotal: 49m 59s\tremaining: 1m 20s\n",
      "487:\ttotal: 50m 5s\tremaining: 1m 13s\n",
      "488:\ttotal: 50m 12s\tremaining: 1m 7s\n",
      "489:\ttotal: 50m 18s\tremaining: 1m 1s\n",
      "490:\ttotal: 50m 25s\tremaining: 55.5s\n",
      "491:\ttotal: 50m 31s\tremaining: 49.3s\n",
      "492:\ttotal: 50m 37s\tremaining: 43.1s\n",
      "493:\ttotal: 50m 42s\tremaining: 37s\n",
      "494:\ttotal: 50m 48s\tremaining: 30.8s\n",
      "495:\ttotal: 50m 53s\tremaining: 24.6s\n",
      "496:\ttotal: 51m 1s\tremaining: 18.5s\n",
      "497:\ttotal: 51m 7s\tremaining: 12.3s\n",
      "498:\ttotal: 51m 14s\tremaining: 6.16s\n",
      "499:\ttotal: 51m 19s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f10f7472550>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(\n",
    "    **params,\n",
    "    eval_metric=\"AUC\",\n",
    "    od_type='Iter',\n",
    "    od_wait=40\n",
    ")\n",
    "\n",
    "model.fit(train, y_train, cat_features=categorical_features_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model to disk\n",
    "model.save_model('catboost_model.dump')\n",
    "#load\n",
    "#model = CatBoostClassifier()\n",
    "#model.load_model('catboost_model.dump');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "submisstion = model.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = str(datetime.datetime.now())[:-7] + '_submission.csv'\n",
    "sub = pd.Series(submisstion, name='target')\n",
    "sub.to_csv(filename, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train with some randomly added na for contract variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "#np.random.seed(42)\n",
    "for i in tqdm.tqdm_notebook(range(100)):\n",
    "    X_train = train.copy()\n",
    "    \n",
    "    #randomly put missing contract in train data\n",
    "    _idx = np.random.choice(X_train.index, size=X_train.shape[0]//20, replace=False)\n",
    "    X_train.loc[_idx, categ_to_impute].fillna('NAN', inplace=True)\n",
    "    X_train.loc[_idx, quanti_contract].fillna(-999, inplace=True)\n",
    "    X_train.loc[_idx, date_contract].fillna(datetime.datetime(1970, 1, 1), inplace=True)\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=1000,\n",
    "        depth=6,\n",
    "        thread_count=12,\n",
    "        border_count=128,\n",
    "        learning_rate=0.015,\n",
    "        random_seed=np.random.randint(10**10),\n",
    "        logging_level='Silent'\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y)\n",
    "    models.append(model.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for _model in tqdm.tqdm_notebook(models):\n",
    "    predictions.append(_model.predict_proba(X_test)[:,1])\n",
    "    \n",
    "predictions = np.vstack(predictions).T.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction = np.hstack([predictions, predictions2]).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost and lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid1 = {'max_depth':[10],\n",
    "               'min_child_weight':[2]}\n",
    "\n",
    "model_xgb = XGBClassifier(learning_rate =0.1, \n",
    "                      n_estimators=200, \n",
    "                      max_depth=10,\n",
    "                      min_child_weight=1, \n",
    "                      gamma=0, \n",
    "                      subsample=0.8, \n",
    "                      colsample_bytree=0.8,\n",
    "                      objective= 'binary:logistic', \n",
    "                      nthread=7, \n",
    "                      scale_pos_weight=1, \n",
    "                      eval_metric='auc',\n",
    "                      seed=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb.fit(X_train_train, y_train_train, eval_set=[(X_train_val, y_train_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gbm = lightgbm.LGBMClassifier(\n",
    "    seed=np.random.randint(10**10),\n",
    "    n_estimators=500,\n",
    "    max_depth=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gbm.fit(X_train_train, y_train_train, \n",
    "              eval_set=[(X_train_val, y_train_val)], \n",
    "              eval_metric='auc', \n",
    "              categorical_feature=categorical_features_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
