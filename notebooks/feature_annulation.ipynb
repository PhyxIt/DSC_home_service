{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import sklearn\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from sklearn import model_selection , metrics   #Additional scklearn functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('../data/merged_data/train.pkl')\n",
    "train = train.iloc[0:5,:]\n",
    "history = pd.read_pickle('../data/merged_data/history.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = history.loc[~history.MILLESIME.isin(['2012.0', '2013.0', '2014.0']), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_selected_variables(df, test, categ, quanti, dates):\n",
    "    _df = df.copy()\n",
    "    _test = test.copy() if test is not None else None\n",
    "    \n",
    "    replace = _df[categ].mode()\n",
    "    replace_values = {k:v.iloc[0] for k,v in replace.items()}\n",
    "    _df.fillna(replace_values, inplace=True)\n",
    "\n",
    "    replace_quanti = _df[quanti].mean()\n",
    "    _df.fillna(replace_quanti, inplace=True)\n",
    "\n",
    "    _df[dates] = _df[dates].fillna(method='pad')\n",
    "    \n",
    "    if test is not None:\n",
    "        _test.fillna(replace_values, inplace=True)\n",
    "        _test.fillna(replace_quanti, inplace=True)\n",
    "        _test[dates] = _df[dates].fillna(method='pad')\n",
    "    \n",
    "    return _df, _test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace = train[categoricals].mode()\n",
    "#replace_values = {k:v.iloc[0] for k,v in replace.items()}\n",
    "def impute_contract_variables(df):\n",
    "    _df = df.copy()\n",
    "    \n",
    "    for var in categ_contract:\n",
    "        try:\n",
    "            _df[var] = _df[var].fillna('NAN')\n",
    "        except ValueError as e:\n",
    "            _df[var] = _df[var].cat.add_categories(['NAN'])\n",
    "            _df[var] = _df[var].fillna('NAN') \n",
    "        \n",
    "    _df[quanti_contract] = _df[quanti_contract].fillna(-9999)\n",
    "    _df[date_contract] = _df[date_contract].fillna(datetime.datetime(1970, 1, 1))\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = list(train.columns[train.dtypes == 'category'])\n",
    "quantitative = ['NB_PASSAGE', 'POINTS_FIDEL', 'CONTRAT_TARIF', 'PRIX_FACTURE']\n",
    "dates = list(train.columns[train.dtypes == 'datetime64[ns]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_variables = [ 'UPD_DATE', 'DATE_DEBUT', 'DATE_FIN', 'STS_CODE', 'OPTION', 'FORMULE', 'CONTRAT_TARIF', 'PRIX_FACTURE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute without contract\n",
    "categ_to_impute = list(set(categoricals) - set(contract_variables))\n",
    "quanti_to_impute = list(set(quantitative) - set(contract_variables))\n",
    "date_to_impute = list(set(dates) - set(contract_variables))\n",
    "\n",
    "#impute contract\n",
    "categ_contract = list(set(categoricals).intersection(set(contract_variables)))\n",
    "quanti_contract = list(set(quantitative).intersection(set(contract_variables)))\n",
    "date_contract = list(set(dates).intersection(set(contract_variables)))\n",
    "\n",
    "\n",
    "#train and test are filled with values taken from train\n",
    "#contract and other variables are imputed separatly (need to import some NAN in train set)\n",
    "history, _ = impute_selected_variables(history, None, categ_to_impute, quanti_to_impute, date_to_impute)\n",
    "history = impute_contract_variables(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_train_features(history, train):\n",
    "    cols_to_keep = list(set(train.columns) - set(['target']))\n",
    "    history_light = history[cols_to_keep].copy()\n",
    "    history_light['canceled'] = ~history['MOTIF_ANNULATION_CODE'].isnull()\n",
    "    \n",
    "    return history_light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_variables(df):\n",
    "    drop = ['INSTANCE_ID',\n",
    "    'INCIDENT_NUMBER',\n",
    "#       'AUTEUR_INCIDENT', # 2088 modalities\n",
    "        'TYPE_VOIE',\n",
    "        'NATURE_CODE', # 313 modalities, need to be splitted in 5 modalities\n",
    "#            'MARQUE_LIB', # 167 modalities\n",
    "#            'OPTION', # 80 modalities, extract options\n",
    "        'MODELE_CODE', # 10k modalities\n",
    "#            'COMMENTAIRE_BI', # NLP 400k modalities\n",
    "#             'RESOURCE_ID', # 4033 modalities\n",
    "        'CODE_POSTAL', # 5800 modalities (only get first 2 numbers ?)\n",
    "        'L2_ORGA_CODE_POSTAL', # 147 modalities (might be redondent with L2_ORGANISATION_ID)\n",
    "#            'L2_ORGANISATION_ID' #151 modalities\n",
    "        'L2_ORGA_VILLE', # 146, might be redondent with other organisation variables\n",
    "        'RACHAT_CODE' # 312 modalities (try binarising ?)         \n",
    "#            'CODE_INSTALLATION' # 17 modalities\n",
    "       ]\n",
    "    return df.drop(drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commentaire_bi(df):\n",
    "    _df = df.copy()\n",
    "    \n",
    "    _df.COMMENTAIRE_BI = _df.COMMENTAIRE_BI.str.upper()\n",
    "    COMMENTAIRE_BI_vc = _df.COMMENTAIRE_BI.value_counts()\n",
    "    common_commentaire_bi = COMMENTAIRE_BI_vc[COMMENTAIRE_BI_vc > 100].index\n",
    "    _df['COMMENTAIRE_BI_common'] = _df.COMMENTAIRE_BI.where(_df.COMMENTAIRE_BI.isin(common_commentaire_bi), \"Rare\")\n",
    "    \n",
    "    _df['nb_char_commentaire'] = [len(txt) for txt in _df.COMMENTAIRE_BI]\n",
    "    _df['nb_mots_commentaire'] = [len(txt.split()) for txt in _df.COMMENTAIRE_BI]\n",
    "    _df['has_number_commentaire'] = [any(char.isdigit() for char in txt) for txt in _df.COMMENTAIRE_BI]\n",
    "    _df['is_empty_commentaire'] = [(txt == '.') for txt in _df.COMMENTAIRE_BI]\n",
    "    _df.drop('COMMENTAIRE_BI', axis=1, inplace=True)\n",
    "    \n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: use dt series accessor\n",
    "def add_dates_features(data):\n",
    "    data['age_installation'] = (data['CRE_DATE_GZL'] - data['INSTALL_DATE']).dt.days // 365\n",
    "    data['mois_appel'] = data['CRE_DATE_GZL'].map(lambda x: x.month)\n",
    "    data['joursemaine_appel'] = data['CRE_DATE_GZL'].map(lambda x: x.isoweekday()) #integer, might be considered categorical\n",
    "    data['jour_appel'] = data['CRE_DATE_GZL'].map(lambda x: x.day)\n",
    "    data['mois_intervention'] = data['SCHEDULED_START_DATE'].map(lambda x: x.month)\n",
    "    data['joursemaine_intervention'] = data['SCHEDULED_START_DATE'].map(lambda x: x.isoweekday()) #integer, might be considered categorical\n",
    "    data['jour_intervention'] = data['SCHEDULED_START_DATE'].map(lambda x: x.day)\n",
    "    data['duree_avant_intervention'] = (data['SCHEDULED_START_DATE'] - data['CRE_DATE_GZL']).dt.days\n",
    "    data['duree_prevue'] = (data['SCHEDULED_END_DATE'] - data['SCHEDULED_START_DATE']).dt.days\n",
    "    data['temps_depuis_debut_contrat'] = (data['CRE_DATE_GZL'] - data['DATE_DEBUT']).dt.days\n",
    "    data['temps_jusqua_fin_contrat'] = (data['CRE_DATE_GZL'] - data['DATE_FIN']).dt.days  #souvent nan ? (mettre 0)\n",
    "    data['temps_depuis_maj_contrat'] = (data['CRE_DATE_GZL'] - data['UPD_DATE']).dt.days \n",
    "\n",
    "    data.drop(['CRE_DATE_GZL', 'INSTALL_DATE', 'SCHEDULED_START_DATE', 'SCHEDULED_END_DATE', 'DATE_DEBUT', 'DATE_FIN', 'UPD_DATE'], axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = keep_train_features(history, train)\n",
    "history = drop_variables(history)\n",
    "history = commentaire_bi(history)\n",
    "history = add_dates_features(history)\n",
    "#history.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = history['canceled']\n",
    "X = history.drop('canceled', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict on train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_ratio = sum(y==False) / sum(y==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = X.select_dtypes(include=['category', 'bool', 'object']).columns\n",
    "categorical_features_indices = [X.columns.get_loc(cat) for cat in categoricals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    iterations=50,\n",
    "    eval_metric=\"AUC\",\n",
    "    scale_pos_weight=pos_neg_ratio,\n",
    "    learning_rate=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 10.3s\tremaining: 8m 26s\n",
      "1:\ttotal: 25.2s\tremaining: 10m 4s\n",
      "2:\ttotal: 40.6s\tremaining: 10m 35s\n",
      "3:\ttotal: 55.8s\tremaining: 10m 41s\n",
      "4:\ttotal: 1m 8s\tremaining: 10m 19s\n",
      "5:\ttotal: 1m 21s\tremaining: 9m 54s\n",
      "6:\ttotal: 1m 34s\tremaining: 9m 41s\n",
      "7:\ttotal: 1m 47s\tremaining: 9m 25s\n",
      "8:\ttotal: 2m\tremaining: 9m 9s\n",
      "9:\ttotal: 2m 10s\tremaining: 8m 40s\n",
      "10:\ttotal: 2m 22s\tremaining: 8m 25s\n",
      "11:\ttotal: 2m 35s\tremaining: 8m 11s\n",
      "12:\ttotal: 2m 46s\tremaining: 7m 54s\n",
      "13:\ttotal: 2m 58s\tremaining: 7m 39s\n",
      "14:\ttotal: 3m 10s\tremaining: 7m 25s\n",
      "15:\ttotal: 3m 23s\tremaining: 7m 11s\n",
      "16:\ttotal: 3m 35s\tremaining: 6m 57s\n",
      "17:\ttotal: 3m 50s\tremaining: 6m 50s\n",
      "18:\ttotal: 4m 5s\tremaining: 6m 40s\n",
      "19:\ttotal: 4m 18s\tremaining: 6m 28s\n",
      "20:\ttotal: 4m 34s\tremaining: 6m 19s\n",
      "21:\ttotal: 4m 46s\tremaining: 6m 4s\n",
      "22:\ttotal: 4m 57s\tremaining: 5m 49s\n",
      "23:\ttotal: 5m 12s\tremaining: 5m 38s\n",
      "24:\ttotal: 5m 25s\tremaining: 5m 25s\n",
      "25:\ttotal: 5m 38s\tremaining: 5m 12s\n",
      "26:\ttotal: 5m 54s\tremaining: 5m 1s\n",
      "27:\ttotal: 6m 7s\tremaining: 4m 48s\n",
      "28:\ttotal: 6m 21s\tremaining: 4m 36s\n",
      "29:\ttotal: 6m 34s\tremaining: 4m 22s\n",
      "30:\ttotal: 6m 47s\tremaining: 4m 9s\n",
      "31:\ttotal: 7m 3s\tremaining: 3m 58s\n",
      "32:\ttotal: 7m 16s\tremaining: 3m 44s\n",
      "33:\ttotal: 7m 33s\tremaining: 3m 33s\n",
      "34:\ttotal: 7m 48s\tremaining: 3m 20s\n",
      "35:\ttotal: 8m 6s\tremaining: 3m 9s\n",
      "36:\ttotal: 8m 21s\tremaining: 2m 56s\n",
      "37:\ttotal: 8m 35s\tremaining: 2m 42s\n",
      "38:\ttotal: 8m 49s\tremaining: 2m 29s\n",
      "39:\ttotal: 9m 7s\tremaining: 2m 16s\n",
      "40:\ttotal: 9m 24s\tremaining: 2m 3s\n",
      "41:\ttotal: 9m 41s\tremaining: 1m 50s\n",
      "42:\ttotal: 9m 54s\tremaining: 1m 36s\n",
      "43:\ttotal: 10m 9s\tremaining: 1m 23s\n",
      "44:\ttotal: 10m 26s\tremaining: 1m 9s\n",
      "45:\ttotal: 10m 39s\tremaining: 55.6s\n",
      "46:\ttotal: 10m 53s\tremaining: 41.7s\n",
      "47:\ttotal: 11m 9s\tremaining: 27.9s\n",
      "48:\ttotal: 11m 22s\tremaining: 13.9s\n",
      "49:\ttotal: 11m 33s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fda47794400>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X, y,\n",
    "    cat_features=categorical_features_indices,\n",
    "    logging_level='Verbose'  # you can uncomment this for text output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('../data/merged_data/train.pkl')\n",
    "train = train.drop('target', axis=1)\n",
    "\n",
    "train, _ = impute_selected_variables(train, None, categ_to_impute, quanti_to_impute, date_to_impute)\n",
    "train = impute_contract_variables(train)\n",
    "\n",
    "train = drop_variables(train)\n",
    "train = commentaire_bi(train)\n",
    "train = add_dates_features(train)\n",
    "train = train[X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "canceled_pred = model.predict(train)\n",
    "canceled_proba_pred = model.predict_proba(train)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_canceled = pd.DataFrame({'canceled_pred': canceled_pred,\n",
    "                                 'canceled_proba_pred': canceled_proba_pred})\n",
    "features_canceled.to_csv('features_canceled_train.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle('../data/merged_data/test.pkl')\n",
    "\n",
    "test, _ = impute_selected_variables(test, None, categ_to_impute, quanti_to_impute, date_to_impute)\n",
    "test = impute_contract_variables(test)\n",
    "\n",
    "test = drop_variables(test)\n",
    "test = commentaire_bi(test)\n",
    "test = add_dates_features(test)\n",
    "test = test[X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "canceled_pred = model.predict(test)\n",
    "canceled_proba_pred = model.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_canceled = pd.DataFrame({'canceled_pred': canceled_pred,\n",
    "                                 'canceled_proba_pred': canceled_proba_pred})\n",
    "features_canceled.to_csv('features_canceled_test.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_train, X_train_val, y_train_train, y_train_val = sklearn.model_selection.train_test_split(X, y, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_ratio =  sum(y_train_train==False) / sum(y_train_train==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = X_train_train.select_dtypes(include=['category', 'bool', 'object']).columns\n",
    "categorical_features_indices = [X_train_train.columns.get_loc(cat) for cat in categoricals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    iterations=50,\n",
    "    eval_metric=\"AUC\",\n",
    "    random_seed=42,\n",
    "    od_type='Iter',\n",
    "    od_wait=40,\n",
    "    use_best_model=True,\n",
    "    scale_pos_weight=pos_neg_ratio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train_train, y_train_train,\n",
    "    cat_features=categorical_features_indices,\n",
    "    eval_set=(X_train_val, y_train_val),\n",
    "    logging_level='Verbose'  # you can uncomment this for text output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
